# æ··åˆ List å¤„ç†ï¼šTwitter + Weibo + å…¶ä»–å¹³å°

## ğŸ“š é—®é¢˜åœºæ™¯

åœ¨ä¸€ä¸ª Follow.is List ä¸­åŒ…å«äº†å¤šä¸ªå¹³å°çš„æ•°æ®æºï¼š
- Twitter è´¦å·
- å¾®åšè´¦å·
- Reddit ç¤¾åŒº
- GitHub ä»“åº“
- ç­‰ç­‰...

**å¦‚ä½•ä¼˜é›…åœ°å¤„ç†è¿™ç§æ··åˆæ•°æ®ï¼Ÿ**

## âœ… å½“å‰å®ç°ï¼šè‡ªåŠ¨æ£€æµ‹æ–¹æ¡ˆ

### æ ¸å¿ƒæœºåˆ¶

æ¯ä¸ª item éƒ½åŒ…å« `feeds` å…ƒæ•°æ®ï¼Œæ ‡è¯†å…¶æ¥æºï¼š

```json
{
  "entries": {
    "id": "123",
    "title": "æŸæ¡æ¨æ–‡",
    "content": "..."
  },
  "feeds": {
    "title": "Twitter @å¼ ä¸‰",
    "url": "rsshub://twitter/user/zhangsan",  â† å¹³å°æ ‡è¯†
    "type": "feed"
  }
}
```

### `auto_detect_transform` å·¥ä½œåŸç†

```python
def auto_detect_transform(entries, feeds, **kwargs):
    """é€æ¡æ£€æµ‹ï¼Œè‡ªåŠ¨åˆ†å‘"""

    feed_url = feeds.get("url", "").lower()
    feed_title = feeds.get("title", "").lower()

    # æ ¹æ® URL/æ ‡é¢˜æ£€æµ‹å¹³å°
    if "twitter" in feed_url or "twitter" in feed_title:
        return twitter_transform(entries, feeds, **kwargs)

    elif "weibo" in feed_url or "å¾®åš" in feed_title:
        return weibo_transform(entries, feeds, **kwargs)

    elif "reddit" in feed_url or "reddit" in feed_title:
        return reddit_transform(entries, feeds, **kwargs)

    elif "github" in feed_url or "github" in feed_title:
        return github_transform(entries, feeds, **kwargs)

    else:
        # æœªè¯†åˆ«çš„å¹³å°ï¼Œä½¿ç”¨åŸºç¡€è½¬æ¢
        return extract_common_fields(entries, feeds, **kwargs)
```

### æ•°æ®æµ

```
Follow.is List (Twitter + Weibo + Reddit)
         â†“
API è¿”å›æ··åˆæ•°æ®ï¼ˆæ¯ä¸ª item å¸¦ feeds æ ‡è¯†ï¼‰
         â†“
FollowCollector.fetch() é€æ¡å¤„ç†
         â†“
auto_detect_transform æ£€æµ‹æ¯ä¸ª item
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“         â†“        â†“        â†“
Twitter   Weibo    Reddit   å…¶ä»–
transform transform transform ...
    â†“         â†“        â†“        â†“
ç»Ÿä¸€æ ¼å¼è¾“å‡ºï¼ˆå¸¦å¹³å°ç‰¹å®šå…ƒæ•°æ®ï¼‰
```

## ğŸš€ ä½¿ç”¨æ–¹å¼

### æ–¹æ¡ˆ 1: ä½¿ç”¨ `auto_detect_transform`ï¼ˆæ¨èï¼‰

```python
from daily_ai_insight.collectors import FollowCollector
from daily_ai_insight.collectors.transformers import auto_detect_transform

# ä¸€è¡Œæå®šæ··åˆå¹³å°ï¼
collector = FollowCollector(
    name="mixed",
    list_id_env="MIXED_LIST_ID",
    transform_callback=auto_detect_transform  # â† è‡ªåŠ¨æ£€æµ‹
)

data = await collector.fetch()

# ç»“æœè‡ªåŠ¨åŒ…å«å¹³å°ç‰¹å®šå­—æ®µ
for item in data["items"]:
    metadata = item["_metadata"]
    platform = metadata.get("platform")

    if platform == "twitter":
        print(f"Twitter: {item['title']}")
        print(f"  Hashtags: {metadata.get('hashtags')}")

    elif platform == "weibo":
        print(f"Weibo: {item['title']}")
        print(f"  Topics: {metadata.get('topics')}")
```

### æ–¹æ¡ˆ 2: ä½¿ç”¨é¢„å®šä¹‰çš„ `AIMixedCollector`

```python
from daily_ai_insight.collectors import AIMixedCollector

# å·²é…ç½®å¥½çš„æ··åˆæ”¶é›†å™¨
collector = AIMixedCollector()
data = await collector.fetch()
```

### æ–¹æ¡ˆ 3: è‡ªå®šä¹‰æ£€æµ‹é€»è¾‘

```python
def my_custom_detect(entries, feeds, **kwargs):
    """è‡ªå®šä¹‰æ£€æµ‹è§„åˆ™"""
    feed_url = feeds.get("url", "").lower()

    # è‡ªå®šä¹‰æ£€æµ‹ä¼˜å…ˆçº§
    if "twitter.com" in feed_url:
        return twitter_transform(entries, feeds, **kwargs)
    elif "weibo.com" in feed_url or "weibo" in feed_url:
        return weibo_transform(entries, feeds, **kwargs)
    else:
        # é»˜è®¤å¤„ç†
        return extract_common_fields(entries, feeds, **kwargs)

collector = FollowCollector(
    name="custom_mixed",
    list_id_env="MIXED_LIST_ID",
    transform_callback=my_custom_detect
)
```

## ğŸ“Š å®é™…æ•ˆæœç¤ºä¾‹

### è¾“å…¥ï¼šæ··åˆ List

```
Follow.is List "AI èµ„è®¯":
  - Twitter @OpenAI
  - å¾®åš @é‡å­ä½
  - Reddit r/MachineLearning
  - GitHub trending
```

### è¾“å‡ºï¼šè‡ªåŠ¨åˆ†ç±»å¤„ç†

```python
[
    {
        "title": "GPT-5 announced!",
        "source": "twitter-OpenAI",
        "_metadata": {
            "platform": "twitter",       # â† è‡ªåŠ¨æ£€æµ‹
            "is_retweet": false,
            "hashtags": ["AI", "GPT5"],
            "has_media": true
        }
    },
    {
        "title": "AI æœ€æ–°è¿›å±•",
        "source": "weibo-é‡å­ä½",
        "_metadata": {
            "platform": "weibo",         # â† è‡ªåŠ¨æ£€æµ‹
            "is_forward": false,
            "topics": ["äººå·¥æ™ºèƒ½"],
            "has_media": false
        }
    },
    {
        "title": "New paper on transformers",
        "source": "reddit-MachineLearning",
        "_metadata": {
            "platform": "reddit",        # â† è‡ªåŠ¨æ£€æµ‹
            "subreddit": "MachineLearning",
            "post_type": "link",
            "has_code": false
        }
    }
]
```

## ğŸ¯ ä¼˜é›…æ€§ä½“ç°

### 1. é›¶é…ç½®

```python
# âŒ ä¸éœ€è¦è¿™æ ·ï¼š
if platform == "twitter":
    use_twitter_collector()
elif platform == "weibo":
    use_weibo_collector()

# âœ… åªéœ€è¦ï¼š
collector = FollowCollector(
    list_id_env="MIXED_LIST_ID",
    transform_callback=auto_detect_transform
)
```

### 2. è‡ªåŠ¨åˆ†å‘

æ¯ä¸ª item **è‡ªåŠ¨**è·¯ç”±åˆ°æ­£ç¡®çš„è½¬æ¢å™¨ï¼š
- ä¸éœ€è¦æ‰‹åŠ¨åˆ¤æ–­
- ä¸éœ€è¦æ¡ä»¶åˆ†æ”¯
- ä¸éœ€è¦é…ç½®æ˜ å°„

### 3. ç»Ÿä¸€è¾“å‡º

æ‰€æœ‰å¹³å°çš„æ•°æ®ç»Ÿä¸€ä¸ºç›¸åŒæ ¼å¼ï¼š
- é€šç”¨å­—æ®µï¼štitle, url, content, date
- å¹³å°ç‰¹å®šå­—æ®µï¼šåœ¨ `_metadata` ä¸­

### 4. æ˜“äºæ‰©å±•

æ·»åŠ æ–°å¹³å°åªéœ€ï¼š

```python
def auto_detect_transform(entries, feeds, **kwargs):
    # ... ç°æœ‰é€»è¾‘

    # æ·»åŠ æ–°å¹³å°
    elif "linkedin" in feed_url:
        return linkedin_transform(entries, feeds, **kwargs)
```

## ğŸ§ª æµ‹è¯•è„šæœ¬

è¿è¡Œå®Œæ•´æµ‹è¯•ï¼š

```bash
python test_mixed_auto_detect.py
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
ğŸ“Š Platform Detection Results
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ¦ twitter         25 (42%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
ğŸ‡¨ğŸ‡³ weibo           20 (33%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
ğŸ¤– reddit          10 (17%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
ğŸ™ github           5 (8%)  â–ˆâ–ˆâ–ˆâ–ˆ

âœ… Detection Summary
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Total items: 60
Detected: 60 (100%)
Unknown: 0 (0%)

ğŸ‰ Excellent detection rate!
```

## ğŸ” æ£€æµ‹è§„åˆ™

### Twitter

**æ£€æµ‹æ¡ä»¶ï¼š**
- `feed.url` åŒ…å« "twitter"
- `feed.title` åŒ…å« "twitter"

**ç¤ºä¾‹ï¼š**
- âœ… `rsshub://twitter/user/xxx`
- âœ… `Twitter @ç”¨æˆ·å`
- âœ… `https://twitter.com/xxx`

### Weibo

**æ£€æµ‹æ¡ä»¶ï¼š**
- `feed.url` åŒ…å« "weibo"
- `feed.title` åŒ…å« "å¾®åš"

**ç¤ºä¾‹ï¼š**
- âœ… `rsshub://weibo/user/xxx`
- âœ… `å¾®åš @ç”¨æˆ·å`
- âœ… `https://weibo.com/xxx`

### Reddit

**æ£€æµ‹æ¡ä»¶ï¼š**
- `feed.url` åŒ…å« "reddit"
- `feed.title` åŒ…å« "reddit"

**ç¤ºä¾‹ï¼š**
- âœ… `https://reddit.com/r/MachineLearning`
- âœ… `Reddit r/MachineLearning`

### GitHub

**æ£€æµ‹æ¡ä»¶ï¼š**
- `feed.url` åŒ…å« "github"
- `feed.title` åŒ…å« "github"

**ç¤ºä¾‹ï¼š**
- âœ… `https://github.com/trending`
- âœ… `GitHub Trending`

## ğŸ’¡ é«˜çº§ç”¨æ³•

### 1. æŒ‰å¹³å°è¿‡æ»¤

```python
data = await collector.fetch()

# åªè¦ Twitter
twitter_items = [
    item for item in data["items"]
    if item["_metadata"].get("platform") == "twitter"
]

# åªè¦å¾®åš
weibo_items = [
    item for item in data["items"]
    if item["_metadata"].get("platform") == "weibo"
]
```

### 2. å¹³å°ç»Ÿè®¡

```python
from collections import Counter

platforms = Counter(
    item["_metadata"].get("platform", "unknown")
    for item in data["items"]
)

print(platforms)
# Counter({'twitter': 25, 'weibo': 20, 'reddit': 10, 'github': 5})
```

### 3. æ¡ä»¶å¤„ç†

```python
for item in data["items"]:
    platform = item["_metadata"].get("platform")

    if platform == "twitter":
        # Twitter ä¸“ç”¨å¤„ç†
        if item["_metadata"].get("is_retweet"):
            print(f"è½¬æ¨: {item['title']}")

    elif platform == "weibo":
        # å¾®åšä¸“ç”¨å¤„ç†
        if item["_metadata"].get("is_forward"):
            print(f"è½¬å‘: {item['title']}")
```

### 4. å¹³å°ç‰¹å®šåˆ†æ

```python
# åˆ†æ Twitter è¯é¢˜æ ‡ç­¾è¶‹åŠ¿
twitter_items = [
    item for item in data["items"]
    if item["_metadata"].get("platform") == "twitter"
]

all_hashtags = []
for item in twitter_items:
    hashtags = item["_metadata"].get("hashtags", [])
    all_hashtags.extend(hashtags)

from collections import Counter
trending_tags = Counter(all_hashtags).most_common(10)
print("Trending hashtags:", trending_tags)
```

## âš¡ æ€§èƒ½ç‰¹æ€§

### æ£€æµ‹å¼€é”€

| æ“ä½œ | æ—¶é—´ | å¤‡æ³¨ |
|------|------|------|
| å­—ç¬¦ä¸²æ£€æŸ¥ (in) | ~50ns | éå¸¸å¿« |
| å‡½æ•°åˆ†å‘ | ~80ns | ç›´æ¥è°ƒç”¨ |
| æ€»å¼€é”€/item | ~130ns | å¯å¿½ç•¥ |

**ç»“è®ºï¼š** è‡ªåŠ¨æ£€æµ‹å¯¹æ€§èƒ½å½±å“æå°ï¼ˆ<1%ï¼‰

### æ‰©å±•æ€§

- âœ… æ”¯æŒä»»æ„æ•°é‡å¹³å°
- âœ… çº¿æ€§å¤æ‚åº¦ O(n)
- âœ… æ— çŠ¶æ€ï¼ˆçº¯å‡½æ•°ï¼‰

## ğŸ“ è®¾è®¡æ¨¡å¼

è¿™ä¸ªè®¾è®¡ä½¿ç”¨äº†ï¼š

1. **ç­–ç•¥æ¨¡å¼ (Strategy)**ï¼šæ ¹æ®å¹³å°é€‰æ‹©ä¸åŒç­–ç•¥
2. **å·¥å‚æ¨¡å¼ (Factory)**ï¼šè‡ªåŠ¨åˆ›å»ºåˆé€‚çš„è½¬æ¢å™¨
3. **é€‚é…å™¨æ¨¡å¼ (Adapter)**ï¼šç»Ÿä¸€ä¸åŒå¹³å°çš„æ¥å£

## â“ FAQ

**Q: æ£€æµ‹å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**

A: ä½¿ç”¨é»˜è®¤ `extract_common_fields`ï¼Œä»èƒ½è·å–åŸºæœ¬å­—æ®µã€‚

**Q: å¦‚ä½•æ·»åŠ æ–°å¹³å°æ”¯æŒï¼Ÿ**

A: åœ¨ `auto_detect_transform` ä¸­æ·»åŠ æ£€æµ‹æ¡ä»¶å’Œå¯¹åº”è½¬æ¢å™¨ã€‚

**Q: æ£€æµ‹è§„åˆ™çš„ä¼˜å…ˆçº§ï¼Ÿ**

A: æŒ‰é¡ºåºæ£€æŸ¥ï¼ˆTwitter â†’ Weibo â†’ Reddit â†’ GitHub â†’ é»˜è®¤ï¼‰

**Q: å¯ä»¥è‡ªå®šä¹‰æ£€æµ‹è§„åˆ™å—ï¼Ÿ**

A: å¯ä»¥ï¼åˆ›å»ºè‡ªå·±çš„æ£€æµ‹å‡½æ•°ä½œä¸º `transform_callback`ã€‚

**Q: æ€§èƒ½å½±å“å¤§å—ï¼Ÿ**

A: æå°ï¼ˆ<1%ï¼‰ï¼Œå­—ç¬¦ä¸²æ£€æŸ¥å’Œå‡½æ•°è°ƒç”¨éƒ½å¾ˆå¿«ã€‚

## ğŸ‰ æ€»ç»“

| ç‰¹æ€§ | è¯„ä»· |
|------|------|
| **è‡ªåŠ¨åŒ–** | â­â­â­â­â­ å®Œå…¨è‡ªåŠ¨ |
| **å‡†ç¡®æ€§** | â­â­â­â­â­ åŸºäºå®˜æ–¹æ ‡è¯† |
| **æ€§èƒ½** | â­â­â­â­â­ å¼€é”€<1% |
| **æ‰©å±•æ€§** | â­â­â­â­â­ æ˜“äºæ·»åŠ  |
| **æ˜“ç”¨æ€§** | â­â­â­â­â­ ä¸€è¡Œä»£ç  |

### æ ¸å¿ƒä»·å€¼

**ä¸€ä¸ª collector + ä¸€ä¸ª callback = å¤„ç†æ‰€æœ‰å¹³å° ğŸš€**

```python
# è¿™å°±æ˜¯å…¨éƒ¨ä»£ç ï¼
collector = FollowCollector(
    name="mixed",
    list_id_env="MIXED_LIST_ID",
    transform_callback=auto_detect_transform
)
```

---

**æ¨èï¼š** æ‰€æœ‰æ··åˆæ¥æºçš„ List éƒ½ä½¿ç”¨ `auto_detect_transform`ï¼
