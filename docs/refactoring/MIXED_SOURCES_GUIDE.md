# æ··åˆæ¥æºæ”¶é›†å™¨ä½¿ç”¨æŒ‡å—

## ğŸ“š æ¦‚è¿°

å½“ä½ åœ¨ Follow.is ä¸­åˆ›å»ºä¸€ä¸ª **List**ï¼ŒåŒ…å«å¤šä¸ªä¸åŒæ¥æºï¼ˆTwitterã€å¾®åšã€Reddit ç­‰ï¼‰çš„å†…å®¹æ—¶ï¼Œ**ä¸éœ€è¦ä¸ºæ¯ä¸ªæ¥æºåˆ›å»ºå•ç‹¬çš„æ”¶é›†å™¨**ã€‚

ç°æœ‰çš„ `FollowCollector` æ¶æ„å·²ç»å®Œç¾æ”¯æŒæ··åˆæ¥æºï¼

## ğŸ—ï¸ æ¶æ„åŸç†

### Follow.is List vs Feed

- **Feed**: å•ä¸€æ•°æ®æºï¼ˆå¦‚ä¸€ä¸ª RSS feedï¼‰
- **List**: å¤šä¸ª Feed çš„èšåˆé›†åˆ

### API æ•°æ®ç»“æ„

å½“ä½¿ç”¨ `listId` è·å–æ•°æ®æ—¶ï¼ŒAPI ä¼šè‡ªåŠ¨åŒ…å«æ¯ä¸ª item çš„æ¥æºä¿¡æ¯ï¼š

```json
{
  "data": [
    {
      "entries": {
        "id": "123",
        "title": "å†…å®¹æ ‡é¢˜",
        "author": "ä½œè€…å",
        "publishedAt": "2025-11-25T03:00:00Z"
      },
      "feeds": {
        "title": "Twitter @ä½œè€…å",  â† æ¥æºæ ‡è¯†
        "type": "feed",
        "url": "rsshub://twitter/user/..."
      }
    }
  ]
}
```

### FollowCollector çš„å¤„ç†

`FollowCollector` åŸºç±»ä¼šï¼š
1. ä»æ¯ä¸ª item çš„ `feeds` å­—æ®µæå–æ¥æºä¿¡æ¯
2. ä½¿ç”¨ `custom_source_format` å‡½æ•°æ ¼å¼åŒ–æ¥æºåç§°
3. åœ¨æœ€ç»ˆæ•°æ®ä¸­ä¿ç•™ `source` å’Œ `_metadata.feed_title` å­—æ®µ

## ğŸ¯ åˆ›å»ºæ··åˆæ¥æºæ”¶é›†å™¨

### æ­¥éª¤ 1: åˆ›å»ºæ”¶é›†å™¨ç±»

```python
# src/daily_ai_insight/collectors/ai_mixed.py

from .base import FollowCollector

class AIMixedCollector(FollowCollector):
    """Collect AI content from mixed sources."""

    def __init__(self):
        def format_mixed_source(author, feeds):
            """æ™ºèƒ½è¯†åˆ«å¹¶æ ¼å¼åŒ–ä¸åŒæ¥æº."""
            feed_title = feeds.get("title", "")
            feed_url = feeds.get("url", "")

            # æ ¹æ® URL æˆ–æ ‡é¢˜è¯†åˆ«æ¥æº
            if "twitter" in feed_url.lower():
                return f"twitter-{author}"
            elif "weibo" in feed_url.lower():
                return f"weibo-{author}"
            elif "reddit" in feed_url.lower():
                return f"reddit-{author}"
            else:
                return f"{feed_title} - {author}"

        super().__init__(
            name="ai_mixed",
            list_id_env="AI_MIXED_LIST_ID",
            source_name="AI Mixed Sources",
            home_url="https://app.follow.is",
            item_type="article",
            custom_source_format=format_mixed_source
        )
```

### æ­¥éª¤ 2: é…ç½®ç¯å¢ƒå˜é‡

åœ¨ `.env` ä¸­æ·»åŠ ï¼š

```bash
# Follow.is List ID (åŒ…å«å¤šä¸ªæ¥æº)
AI_MIXED_LIST_ID=your_list_id_here

# Follow.is Cookie
FOLO_COOKIE=your_cookie_here
```

### æ­¥éª¤ 3: æ³¨å†Œæ”¶é›†å™¨

åœ¨ `__init__.py` ä¸­å¯¼å‡ºï¼š

```python
from .ai_mixed import AIMixedCollector

__all__ = [
    # ...
    "AIMixedCollector",
]
```

### æ­¥éª¤ 4: ä½¿ç”¨æ”¶é›†å™¨

```python
from daily_ai_insight.collectors import AIMixedCollector

# åˆå§‹åŒ–
collector = AIMixedCollector()

# è·å–æ•°æ®
data = await collector.fetch()

# æŸ¥çœ‹ç»“æœ
for item in data["items"]:
    print(f"æ¥æº: {item['source']}")
    print(f"æ ‡é¢˜: {item['title']}")
    print(f"ä½œè€…: {item['authors']}")
    print(f"è¯¦ç»†æ¥æº: {item['_metadata']['feed_title']}")
    print()
```

## ğŸ“Š è¾“å‡ºç¤ºä¾‹

```python
{
    "title": "Claude Opus 4.5 å‘å¸ƒäº†",
    "url": "https://x.com/someone/status/123",
    "source": "twitter-å¼ ä¸‰",  # è‡ªå®šä¹‰æ ¼å¼åŒ–åçš„æ¥æº
    "authors": [{"name": "å¼ ä¸‰"}],
    "_metadata": {
        "type": "article",
        "feed_title": "Twitter @å¼ ä¸‰"  # åŸå§‹æ¥æºä¿¡æ¯
    }
}

{
    "title": "AI æœ€æ–°è¿›å±•",
    "url": "https://weibo.com/123/456",
    "source": "weibo-æå››",  # è‡ªåŠ¨è¯†åˆ«ä¸ºå¾®åš
    "authors": [{"name": "æå››"}],
    "_metadata": {
        "feed_title": "å¾®åš @æå››"
    }
}
```

## ğŸ¨ é«˜çº§è‡ªå®šä¹‰

### åœºæ™¯ 1: æŒ‰ä¸»é¢˜åˆ†ç±»

```python
def format_by_topic(author, feeds):
    """æŒ‰ä¸»é¢˜åˆ†ç±»æ¥æº."""
    feed_title = feeds.get("title", "").lower()

    # è¯†åˆ«ä¸»é¢˜
    if "research" in feed_title or "paper" in feed_title:
        return f"ç ”ç©¶-{author}"
    elif "news" in feed_title:
        return f"æ–°é—»-{author}"
    else:
        return f"å…¶ä»–-{author}"
```

### åœºæ™¯ 2: ä¿ç•™å®Œæ•´æ¥æº

```python
def format_full_source(author, feeds):
    """ä¿ç•™å®Œæ•´çš„æ¥æºä¿¡æ¯."""
    return feeds.get("title", "Unknown")
```

### åœºæ™¯ 3: ç®€åŒ–æ¥æº

```python
def format_simple(author, feeds):
    """åªæ˜¾ç¤ºä½œè€…å."""
    return author if author else "Anonymous"
```

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. List ç»„ç»‡å»ºè®®

åœ¨ Follow.is ä¸­åˆ›å»ºä¸»é¢˜æ˜ç¡®çš„ Listï¼š
- âœ… "AI èµ„è®¯" List: èšåˆ AI ç›¸å…³çš„ Twitterã€å¾®åšã€åšå®¢
- âœ… "æŠ€æœ¯å‰æ²¿" List: èšåˆæŠ€æœ¯è®ºæ–‡ã€GitHubã€Reddit
- âŒ ä¸è¦: æŠŠæ‰€æœ‰å†…å®¹æ··åœ¨ä¸€ä¸ª List é‡Œ

### 2. æ¥æºè¯†åˆ«ç­–ç•¥

ä¼˜å…ˆçº§é¡ºåºï¼š
1. **Feed URL** (æœ€å¯é ): `rsshub://twitter/...`
2. **Feed Title** (æ¬¡å¯é ): `"Twitter @ç”¨æˆ·å"`
3. **Entry å­—æ®µ** (ä½œä¸ºè¡¥å……): author, url pattern

### 3. æµ‹è¯•å»ºè®®

```python
# æµ‹è¯•ä¸åŒæ¥æºçš„æ ¼å¼åŒ–
test_cases = [
    {
        "author": "å¼ ä¸‰",
        "feeds": {"title": "Twitter @å¼ ä¸‰", "url": "rsshub://twitter/..."}
    },
    {
        "author": "æå››",
        "feeds": {"title": "å¾®åš @æå››", "url": "rsshub://weibo/..."}
    }
]

for case in test_cases:
    result = format_mixed_source(case["author"], case["feeds"])
    print(f"è¾“å…¥: {case['feeds']['title']}")
    print(f"è¾“å‡º: {result}\n")
```

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜ 1: æ‰€æœ‰ item çš„ source éƒ½ä¸€æ ·

**åŸå› **: `custom_source_format` å‡½æ•°æ²¡æœ‰æ­£ç¡®è¯†åˆ«ä¸åŒæ¥æº

**è§£å†³**: æ‰“å° `feeds` å­—æ®µï¼Œæ£€æŸ¥å®é™…çš„æ•°æ®æ ¼å¼ï¼š

```python
def format_mixed_source(author, feeds):
    print(f"DEBUG - feeds: {feeds}")  # è°ƒè¯•è¾“å‡º
    # ... æ ¼å¼åŒ–é€»è¾‘
```

### é—®é¢˜ 2: æŸäº›æ¥æºæ²¡æœ‰è¢«è¯†åˆ«

**åŸå› **: è¯†åˆ«é€»è¾‘ä¸å®Œæ•´

**è§£å†³**: æ·»åŠ æ›´å¤šè¯†åˆ«æ¡ä»¶ï¼Œå¹¶æä¾›é»˜è®¤åˆ†æ”¯ï¼š

```python
# æ·»åŠ  fallback
if "twitter" in url:
    return "twitter"
elif "weibo" in url:
    return "weibo"
else:
    # é»˜è®¤ï¼šä½¿ç”¨ feed title
    return feeds.get("title", "Unknown")
```

## ğŸš€ ç°æˆç¤ºä¾‹

é¡¹ç›®ä¸­å·²åŒ…å«ä¸€ä¸ªå®Œæ•´ç¤ºä¾‹ï¼š`AIMixedCollector`

ä½¿ç”¨æ–¹æ³•ï¼š

```bash
# 1. é…ç½® .env
AI_MIXED_LIST_ID=ä½ çš„List_ID

# 2. æµ‹è¯•
python -c "
import asyncio
from daily_ai_insight.collectors import AIMixedCollector

async def test():
    collector = AIMixedCollector()
    data = await collector.fetch()
    print(f'è·å–äº† {len(data[\"items\"])} æ¡æ•°æ®')

    # ç»Ÿè®¡å„æ¥æºæ•°é‡
    sources = {}
    for item in data['items']:
        source = item['source'].split('-')[0]
        sources[source] = sources.get(source, 0) + 1

    print('æ¥æºåˆ†å¸ƒ:', sources)

asyncio.run(test())
"
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [FollowCollector API æ–‡æ¡£](src/daily_ai_insight/collectors/base.py)
- [Follow.is API æ–‡æ¡£](https://api.follow.is)
- [æ”¶é›†å™¨æµ‹è¯•è„šæœ¬](test_real_data.py)

## â“ FAQ

**Q: éœ€è¦ä¸ºæ¯ä¸ªæ–°çš„æ··åˆ List åˆ›å»ºæ–°çš„æ”¶é›†å™¨ç±»å—ï¼Ÿ**

A: ä¸éœ€è¦ï¼ä½ å¯ä»¥ï¼š
- å¤ç”¨ç°æœ‰æ”¶é›†å™¨ï¼Œåªéœ€æ›´æ”¹ç¯å¢ƒå˜é‡å
- æˆ–åˆ›å»ºä¸€ä¸ªé€šç”¨çš„ `MixedCollector`ï¼Œé€šè¿‡å‚æ•°ä¼ å…¥ List ID

**Q: List é‡Œçš„ Feed æ•°é‡æœ‰é™åˆ¶å—ï¼Ÿ**

A: Follow.is API ä¼šåˆ†é¡µè¿”å›ï¼Œ`FollowCollector` é»˜è®¤è·å– 3 é¡µæ•°æ®ï¼ˆçº¦ 60 itemsï¼‰ã€‚å¯ä»¥é€šè¿‡ä¿®æ”¹ `fetch_pages` å‚æ•°è·å–æ›´å¤šã€‚

**Q: å¦‚ä½•è¿‡æ»¤ç‰¹å®šæ¥æºçš„å†…å®¹ï¼Ÿ**

A: åœ¨æ”¶é›†å™¨çš„ `fetch()` æˆ– `transform()` æ–¹æ³•ä¸­æ·»åŠ è¿‡æ»¤é€»è¾‘ï¼Œæˆ–åœ¨ä½¿ç”¨æ—¶è¿‡æ»¤ï¼š

```python
data = await collector.fetch()
twitter_only = [
    item for item in data["items"]
    if item["source"].startswith("twitter-")
]
```
