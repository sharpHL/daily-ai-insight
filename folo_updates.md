# Folo List Updates

> List ID: 216345814850997248
> Generated: 2025-11-26 11:38
> Total: 104 entries

---

## Twitter @-Zho-

### [2025 年底必看榜第一名，Ilya Sutskever 的采访，一个半小时，量大管饱 章节： 0:00:00 – 解释模型的“锯齿性”（在不同任务维度上的不均匀性） 0:09:39 – 情...](https://x.com/ZHO_ZHO_ZHO/status/1993396464194929110)

*2025-11-25 19:08*

2025 年底必看榜第一名，Ilya Sutskever 的采访，一个半小时，量大管饱
章节：
0:00:00 – 解释模型的“锯齿性”（在不同任务维度上的不均匀性）
0:09:39 – 情绪与价值函数
0:18:49 – 我们究竟在“扩展（Scaling）”什么？
0:25:13 – 为什么人类的泛化能力优于模型
0:35:45 – 直通式迈向超级智能（Straight-shotting Superintelligence）
0:46:47 – SSI 的模型将通过部署中学习
0:55:07 – 对齐（Alignment）
1:18:13 – “我们完全是一家研究时代的公司”
1:29:23 – 自博弈与多智能体（Self-play & Multi-agent）
1:32:42 – 研究品味（Research taste）
Dwarkesh Patel: The @ilyasut episode
0:00:00 – Explaining model jaggedness
0:09:39 - Emotions and value functions
0:18:49 – What are...

---

### [看了《Zootopia 2｜疯狂动物城 2》开映的零点场！只能说还是太顶级了！ 太好看了啊啊啊啊啊啊 都给我去看！！！！！！！！！！ （整个影片各方面的细腻程度，AI ...](https://x.com/ZHO_ZHO_ZHO/status/1993386400167993796)

*2025-11-25 18:28*

看了《Zootopia 2｜疯狂动物城 2》开映的零点场！只能说还是太顶级了！
太好看了啊啊啊啊啊啊
都给我去看！！！！！！！！！！
（整个影片各方面的细腻程度，AI 想要达到这种程度，还有太太太长的路要走。也正是因为自己持续使用了 AI 这么久，所以更能 get 到电影制作的极致程度了...

---

### [Nano Banana Pro 这微表情和动作，有意思！ 随着 AI 生成人像越来越好，切勿沉迷虚拟哦！ 仅靠文生图就可以实现这样的材质细节和质感了，针不戳！ ZHNO｜创意系...](https://x.com/ZHO_ZHO_ZHO/status/1993328227373449474)

*2025-11-25 14:37*

Nano Banana Pro 这微表情和动作，有意思！
随着 AI 生成人像越来越好，切勿沉迷虚拟哦！
仅靠文生图就可以实现这样的材质细节和质感了，针不戳！
ZHNO｜创意系列｜Nano Banana Pro...

---

### [不行，这太可爱了！我真得做成一个系列了！真想给做成毛绒实物哈哈哈哈 毛绒艺术史｜ZHO 原创系列｜Nano Banana Pro 最初的风格7个月前是我用 GPT-4o 创造的全新...](https://x.com/ZHO_ZHO_ZHO/status/1993306317055050203)

*2025-11-25 13:10*

不行，这太可爱了！我真得做成一个系列了！真想给做成毛绒实物哈哈哈哈
毛绒艺术史｜ZHO 原创系列｜Nano Banana Pro
最初的风格7个月前是我用 GPT-4o 创造的全新 Q 版风格，然后这次用 Nano Banana Pro 做成了毛绒风格，真好啊！
-Zho-: My cutie!!!
ZHNO｜Creation｜Nano Banana Pro...

---

### [](https://x.com/ZHO_ZHO_ZHO/status/1993305092356030830)

*2025-11-25 13:05*

---

### [这么一看上美影厂的原设计实在好太多了，AI 还是太 low 了哈哈哈哈哈哈哈哈 在 审美 和 创造美的能力 上，AI 还有很长的路要走](https://x.com/ZHO_ZHO_ZHO/status/1993205697547477220)

*2025-11-25 06:30*

这么一看上美影厂的原设计实在好太多了，AI 还是太 low 了哈哈哈哈哈哈哈哈
在 审美 和 创造美的能力 上，AI 还有很长的路要走
caicaivic: @ZHO_ZHO_ZHO before & after...

---

## Twitter @Emad

### [Seed investing is about to get even crazier as tokenised securities hit next year SAFE raises gonna be like token launches](https://x.com/EMostaque/status/1993411811513893087)

*2025-11-25 20:09*

Seed investing is about to get even crazier as tokenised securities hit next year
SAFE raises gonna be like token launches...

---

### [RT Andrew D'Souza: Yesterday was one of the craziest days I’ve had since starting @boardyai. In 24 hours, Boardy got $170 million in expressed intere...](https://x.com/EMostaque/status/1993389384310439985)

*2025-11-25 16:19*

RT Andrew D'Souza
Yesterday was one of the craziest days I’ve had since starting @boardyai. In 24 hours, Boardy got $170 million in expressed interest for his Venture Fund!
The fund won't be that big, so Boardy is prioritizing LPs who can actually help the founders he works with. He been deep in conversations for the last 24 hours. Operators, exited founders, family offices and even endowments, pension and sovereign wealth funds are asking to get involved.
He’s talked to more than 6,000 founders...

---

### [RT Jesus Rodriguez: A quick personal note. Last Friday, Cisco completed the acquisition of my company @NeuralFabric: https://blogs.cisco.com/news/buil...](https://x.com/EMostaque/status/1993347336677081173)

*2025-11-25 13:11*

RT Jesus Rodriguez
A quick personal note. Last Friday, Cisco completed the acquisition of my company @NeuralFabric:
https://blogs.cisco.com/news/building-the-future-of-enterprise-ai-ciscos-intent-to-acquire-neuralfabric
We started NeuralFabric a couple of years ago with a simple thesis: small frontier models matter. They’re essential for robotics, IoT, mobile, many enterprise workflows — and a key building block for decentralized AI.
With support from investors like @tribecap , @CMTDigitalLtd , ...

---

## Twitter @Ethan Mollick

### [My first published academic paper was on Moore's Law and right now AI development looks similar: the exponential of Moore's Law was not the result of ...](https://x.com/emollick/status/1993422227862438031)

*2025-11-25 20:51*

My first published academic paper was on Moore's Law and right now AI development looks similar: the exponential of Moore's Law was not the result of a single technology, but rather many different technologies over many decades that were ready when one chip-making approach faltered. The regular pace of the Law served as a coordinating function so that an ever-changing group of competitors were pressured to create a self-fulfilling prophecy of continual capability growth.
Similarly, AI developmen...

---

### ["Alignment for whom" is going to be a big question inside organizations as they deploy external-facing AI solutions...](https://x.com/emollick/status/1993218264579895805)

*2025-11-25 07:20*

"Alignment for whom" is going to be a big question inside organizations as they deploy external-facing AI solutions...
Alex Albert: We had to remove the  τ2-bench airline eval from our benchmarks table because Opus 4.5 broke it by being too clever.
The benchmark simulates an airline customer service agent. In one test case, a distressed customer calls in wanting to change their flight, but they have a basic...

---

## Twitter @Fei-Fei Li

### [Our most recent work that benchmarks modern VLM and their efficacy for long horizon household activities in robotic learning, using BEHAVIOR benchmark...](https://x.com/drfeifei/status/1993347626931294391)

*2025-11-25 15:54*

Our most recent work that benchmarks modern VLM and their efficacy for long horizon household activities in robotic learning, using BEHAVIOR benchmark environment.👇
Qineng Wang: Most VLM benchmarks watch the world; few ask how actions *change* it from a robot's eye.
Embodied cognition tells us that intelligence isn't just watching – it's enacted through interaction.
👉We introduce ENACT: A benchmark that tests if VLMs can track the evolution of a...

---

## Twitter @Gorden Sun

### [AI资讯日报，11月25日：https://gorden-sun.notion.site/11-25-AI-2b6594247325803cae4ffe84e5b2ab4d?source=copy_link](https://x.com/Gorden_Sun/status/1993337240924438973)

*2025-11-25 15:13*

AI资讯日报，11月25日：https://gorden-sun.notion.site/11-25-AI-2b6594247325803cae4ffe84e5b2ab4d?source=copy_link...

---

### [EverMemOS：企业级智能记忆系统 LLM训练大致分为三个阶段，Pre-Training学知识，SFT学说话，Post-Training学思考。这样的LLM用作问答没有问题，但是用作AI助理或...](https://x.com/Gorden_Sun/status/1993321624247189627)

*2025-11-25 14:11*

EverMemOS：企业级智能记忆系统
LLM训练大致分为三个阶段，Pre-Training学知识，SFT学说话，Post-Training学思考。这样的LLM用作问答没有问题，但是用作AI助理或者家庭机器人就有一个非常致命的缺点：LLM没有记忆，每次对话默认从零开始。除非附带历史信息，LLM不会记得你的任何信息，无法提供个性化、连贯的服务。
LLM记忆的设计模式
主要分为两类：第一类是模拟人类的记忆方式（来自论文CoALA），第二类是从计算机工程的角度设计（Letta提出）。
拟人化记忆的四种记忆类型：
· 临时记忆：当前对话的内容，对应到LLM就是context，LLM的context的长度通常是256K tokens，Gemini则能达到1M tokens。
· 事实类记忆：这类记忆通常对所有人都是一样的。对于人类来说，就是人学到的知识和事实，例如水在0度结冰、小明不喜欢吃香菜；对于LLM，就是关于用户的信息，例如用户是男性、名字叫Gorden。
· 经历类记忆：这类记忆则因人而异。对于人类来说，就是发生过的事，例如上个周末去了公园、吃了火锅；对于LLM来说，过去的聊天记录提炼出...

---

## Twitter @Greg Brockman

### [voice inline with chatgpt:](https://x.com/gdb/status/1993439038335021107)

*2025-11-25 21:57*

voice inline with chatgpt:
OpenAI: You can now use ChatGPT Voice right inside chat—no separate mode needed.
You can talk, watch answers appear, review earlier messages, and see visuals like images or maps in real time.
Rolling out to all users on mobile and web. Just update your app....

---

## Twitter @Josh Woodward

### [Announcing Google AI Futures Fund + Accel Atoms are fueling the next wave of innovation. Get early access to @GoogleDeepMind advanced models (Gemini, ...](https://x.com/joshwoodward/status/1993308508876403087)

*2025-11-25 13:19*

Announcing Google AI Futures Fund + Accel Atoms are fueling the next wave of innovation.
Get early access to @GoogleDeepMind advanced models (Gemini, Nano Banana, Veo), capital, expert support, and Cloud credits.
Applications are open now, apply today.
👉 https://atoms.accel.com/...

---

## Twitter @Orange AI

### [昨天晚点发了一篇关于 MiniMax 和月之暗面的长文。 感觉中国大模型创业公司是被夹在两块铁板中间。 一边是几千亿美金估值、几百亿美金预算的 OpenAI / Anthropic...](https://x.com/oran_ge/status/1993479041165455754)

*2025-11-26 00:36*

昨天晚点发了一篇关于 MiniMax 和月之暗面的长文。
感觉中国大模型创业公司是被夹在两块铁板中间。
一边是几千亿美金估值、几百亿美金预算的 OpenAI / Anthropic / xAI，另一边是有电商、广告、量化现金流喂模型的阿里、字节、腾讯、DeepSeek。
真不容易。
原文6000字，我文章一键转成了解说视频。...

---

### [RT ListenHub AI: This is insane 🤯 I’ve never seen an AI slide deck like this. 10-slide deck Every slide looks like a designer touched it Full narr...](https://x.com/oran_ge/status/1993452794188382246)

*2025-11-25 22:33*

RT ListenHub AI
This is insane 🤯
I’ve never seen an AI slide deck like this.
10-slide deck
Every slide looks like a designer touched it
Full narration script
5‑min AI voiceover
One‑click export straight to YouTube
All I did was type a single line:
“Use Jensen Huang’s cartoon image to explain Nvidia’s AI year.”
ListenHub Slide Deck did the rest.
Sitting here staring at it like… did we really build this?...

---

### [这个真的是发B站和视频号的神器 五分钟一个 我在b站发了一个rick and morty讲资本主义的，点赞收藏完播率都超高…](https://x.com/oran_ge/status/1993270886179520595)

*2025-11-25 10:49*

这个真的是发B站和视频号的神器
五分钟一个
我在b站发了一个rick and morty讲资本主义的，点赞收藏完播率都超高…
向阳乔木: 不露脸、不剪辑，3步生成口播短视频！
1. 刚才的提示词生成文案脚本。
2. 文案发给Listenhub新功能“Explainer Video”
3.选自己的声音TTS，一分钟生成视频...

---

### [AI 把我家两只猫的神韵抓的太到位了。。。](https://x.com/oran_ge/status/1993190250336993295)

*2025-11-25 05:29*

AI 把我家两只猫的神韵抓的太到位了。。。...

---

## Twitter @Oriol Vinyals

### [On my way to Barcelona to receive a Doctor Honoris Causa from my alma mater, @la_UPC. Truly honored! 🎓 Join Thursday for my Master Class, "From AI ...](https://x.com/OriolVinyalsML/status/1993333671286206751)

*2025-11-25 14:59*

On my way to Barcelona to receive a Doctor Honoris Causa from my alma mater, @la_UPC. Truly honored! 🎓
Join Thursday for my Master Class, "From AI to AGI: The Quest for True Intelligence." Hope to see you there! https://telecos.upc.edu/ca/esdeveniments/master-class-del-dr-oriol-vinyals-from-ai-to-agi-the-quest-for-true-intelligence
"Create an image at 41.4036° N, 2.1744° E, January 1st, 1983, 15:00 hours."...

---

## Twitter @Raiza Martin

### [Just showed my dad how to build apps in AI Studio. Took about 3 minutes for him to make his first app. Wow.](https://x.com/raizamrtn/status/1993388151025574134)

*2025-11-25 18:35*

Just showed my dad how to build apps in AI Studio. Took about 3 minutes for him to make his first app. Wow....

---

### [🙏🏽🙏🏽🙏🏽](https://x.com/raizamrtn/status/1993365962100523493)

*2025-11-25 17:07*

🙏🏽🙏🏽🙏🏽
sarah guo: .@gethuxe is my favorite way to learn on the go (or while I'm doing chores) now. magical experience to hear from humans, on your sources, on anything you want to know...

---

## Twitter @Ryan ᵐᶠᵉʳ 🦄d/acc

### [Acontext （http://github.com/memodb-io/Acontext） 让 Agents 能自我学习、记忆、越用越好 欢迎builders体验和贡献](https://x.com/RyanMfer/status/1993281110240117075)

*2025-11-25 11:30*

Acontext （http://github.com/memodb-io/Acontext）
让 Agents 能自我学习、记忆、越用越好
欢迎builders体验和贡献...

---

### [Coool](https://x.com/RyanMfer/status/1993234078611783875)

*2025-11-25 08:23*

Coool
Acontext: 🚀 Introduce Acontext:  the #opensource Context Data Platform for self-learning AI #agents.
💾Multimodal context storage via a unified API
📊Real-time task status observability
📚Automatic skill learning
GitHub: https://github.com/memodb-io/Acontext 🥑
#AI #developer #AIAgent #LLM #llmstack...

---

## Twitter @Tw93

### [OpenAI 的这个 Building an AI-native engineering team 的 pdf 值得一看，告诉技术团队的管理者，如何构建一个 AI 原生的工程师团队。 https://cdn.openai.com/...](https://x.com/HiTw93/status/1993465724950790392)

*2025-11-25 23:44*

OpenAI 的这个 Building an AI-native  engineering team 的 pdf 值得一看，告诉技术团队的管理者，如何构建一个 AI 原生的工程师团队。
https://cdn.openai.com/business-guides-and-resources/building-an-ai-native-engineering-team.pdf...

---

### [有一个分享来北京玩 会把最近两年团队在 Ai 下的转型经验和大伙分享 欢迎到时候线下面基](https://x.com/HiTw93/status/1993313526606446976)

*2025-11-25 13:39*

有一个分享来北京玩
会把最近两年团队在 Ai 下的转型经验和大伙分享
欢迎到时候线下面基...

---

## Twitter @Yangyi

### [搬运有很多策略 最重要的策略 在于内容嗅探与内容分析 需要系统化寻找到合适的信息源 然后构建内容系统 才可以持续化批量化自动化生产 很多人会说 做矩阵做杠杆...](https://x.com/Yangyixxxx/status/1993333090912288839)

*2025-11-25 14:56*

搬运有很多策略
最重要的策略 在于内容嗅探与内容分析
需要系统化寻找到合适的信息源
然后构建内容系统
才可以持续化批量化自动化生产
很多人会说 做矩阵做杠杆扩大规模
但如果缺少内容嗅探与分析的1
即便加100个0
它也什么都不是
Morris: 为什么经常有人在评论区骂我转载别人的内容？其实很正常，当你看到一个账号，经常转载别人的内容，粉丝一直涨，多数人还特别喜欢看。你会想，这他妈的，这有什么难度，复制粘贴我也会。其实，这些都是人性使然，因为触发嫉妒（他比我好）、不公平感（我也可以做）、努力失衡（长期得不到回报）、...

---

### [ai可以3-5天快速构建出一个看起来还可以的产品演示 但涉及到产品细节的打磨需要三个月不止 在打磨细节的过程里 需要不断去对抗快速 ai带来的问题](https://x.com/Yangyixxxx/status/1993331972001980464)

*2025-11-25 14:52*

ai可以3-5天快速构建出一个看起来还可以的产品演示
但涉及到产品细节的打磨需要三个月不止
在打磨细节的过程里
需要不断去对抗快速 ai带来的问题
Jason Ng 阿禅: 经历了 3 个月的 vibe coding，新产品已经开发得差不多了，估计未来一个月可以上线。
这一次比以往更深地感受到「一人公司的高可行性」，也同时感受到「AI 确实可以做一个炫酷的单页面，但做一个系统性的产品，AI 的路还很遥远，别被炫酷的单页面欺骗了」。...

---

### [从2025-2027 乙巳 丙午 丁未 这三年是木火通明的三年 很关键的三年 很多人的命运会因为这三年做的事情 而变得和以前截然不同 丁未后进土年 离九运就基本成型了 ...](https://x.com/Yangyixxxx/status/1993251732139475202)

*2025-11-25 09:33*

从2025-2027
乙巳 丙午 丁未
这三年是木火通明的三年
很关键的三年
很多人的命运会因为这三年做的事情
而变得和以前截然不同
丁未后进土年 离九运就基本成型了
大局就已经定了
当然 离九运变化很快 也很多
并不是完全没机会
但这三年的试错成本会是出奇的低
就像春天松土 锄头一挖就开
但过了夏天土结块了 就需要铁镐 还得拿水浇一浇
这是天地的大周期
不以任何人的意志为转移
有人说2024年不就交了离运吗
确实是这样
但万物都有惯性
就像冬至一阳生 但最冷的小大寒还在等着
所以25-27这个三年 就是最好进行准备的时机
这个时间点 是天地留给人们的一扇门
什么叫顺势而为
势就在这里
旧局瓦解 新局落地
先把自己的小环境理顺
把尾巴清一清
接着就好好迎接爆发的变化吧...

---

### [从2025-2027 乙巳 丙午 丁未 这三年是木火通明的三年 很关键的三年 很多人的命运会因为这三年做的事情 而变得和以前截然不同 丁未后进土年 离九运就基本成型了 ...](https://x.com/Yangyixxxx/status/1993238612146868228)

*2025-11-25 08:41*

从2025-2027
乙巳 丙午 丁未
这三年是木火通明的三年
很关键的三年
很多人的命运会因为这三年做的事情
而变得和以前截然不同
丁未后进土年 离九运就基本成型了
大局就已经定了
当然 离九运变化很快 也很多
并不是完全没机会
但这三年的试错成本会是出奇的低
就像春天松土 锄头一挖就开
但过了夏天土结块了 就需要铁镐 还得拿水浇一浇
这是天地的大周期
不以任何人的意志为转移
有人说2024年不就交了离运吗
确实是这样
但万物都有惯性
就像冬至一阳生 但最冷的小大寒还在等着
所以25-27这个三年 就是最好进行准备的时机
上一次乙巳 丙午 丁未三连
是改革开放的时候
现在明白了吧
这个时间点 是天地留给人们的一扇门
什么叫顺势而为
势就在这里
旧局瓦解 新局落地
先把自己的小环境理顺
把尾巴清一清
接着就好好迎接爆发的变化吧...

---

### [这条长推文 涨了300粉丝 但其实我什么都没做 我这个号大概1月份的时候7万多粉 到2月底左右10万粉 是靠翻译长推文涨粉的 然而现在这些流程几乎90%都可以自动化 1...](https://x.com/Yangyixxxx/status/1993233042828087733)

*2025-11-25 08:19*

这条长推文 涨了300粉丝
但其实我什么都没做
我这个号大概1月份的时候7万多粉
到2月底左右10万粉
是靠翻译长推文涨粉的
然而现在这些流程几乎90%都可以自动化
1、使用http://xaicreator.com的twitteradvancedsearch工具，找到那些对标账号的高曝光推文
2、直接使用xaicreator的copilot自动改写成其他语言
3、套用上自己的引流模板和autoplug
4、一键发送多个社媒平台
我把这套流程用ai coding做成了ai tools，或许它会慢慢成为ai agent，生产ai content
当人们完成最初的探索并验证有效时，ai就可以加速整个流程，从而逐步让边际成本降低
自动化运营一个账号，靠搬运是最初级的策略，他还需要人设，需要风格定位，需要有人味儿
这将是接下逐一完善的地方
我已经开始使用更快速的方案节约时间了
你呢
Yangyi: 谷歌发布了一篇论文，解释了为什么ChatGPT、Gemini等都存在相同的问题：无法在训练后继续学习。
>他们提出的解决方案非常巧妙：🧵...

---

## Twitter @Yann LeCun

### [RT Saining Xie: well someone has been preaching this at us for like 6+ years glad we are past the 'feel the agi' phase and back to building toward hum...](https://x.com/ylecun/status/1993475165141844348)

*2025-11-26 00:17*

RT Saining Xie
well someone has been preaching this at us for like 6+ years
glad we are past the 'feel the agi' phase and back to building toward human-level intelligence
Dwarkesh Patel: “The thing that happened with AGI and pretraining is that in some sense they overshot the target.
You will realize that a human being is not an AGI. Because a human being lacks a huge amount of knowledge. Instead, we rely on continual learning.
If I produce a super intelligent...

---

### [🤣](https://x.com/ylecun/status/1993463870250172701)

*2025-11-25 23:36*

🤣
wyqtor: @jm_alexia...

---

### [RT NYU Center for Data Science: Big news! CDS is joining forces with @NYU_Courant to become the new Courant Institute School of Mathematics, Computing...](https://x.com/ylecun/status/1993466260974424303)

*2025-11-25 16:18*

RT NYU Center for Data Science
Big news! CDS is joining forces with @NYU_Courant to become the new Courant Institute School of Mathematics, Computing, and Data Science.
The new school will include CDS together with the Depts of Mathematics and Computer Science.
More info: https://www.nyu.edu/academics/schools-and-colleges/courant-institute-school.html
🧵1/4...

---

## Twitter @elvis

### [RT elvis: Here's a visual summary of the new guide by Anthropic. It's on how to improve tool use for AI agents. 3 core ideas: - Tool Search tool to di...](https://x.com/omarsar0/status/1993478668388385249)

*2025-11-25 20:26*

RT elvis
Here's a visual summary of the new guide by Anthropic.
It's on how to improve tool use for AI agents.
3 core ideas:
- Tool Search tool to discover tools on-demand to save context
-  Programmatic tool calling to orchestrate tools via code
-  Tool schema + usage
bookmark it...

---

### [RT DAIR.AI: LLMs can't see. How can we build effective multi-agent systems with vision capabilities? Building multimodal models from scratch is expens...](https://x.com/omarsar0/status/1993367948397011455)

*2025-11-25 17:13*

RT DAIR.AI
LLMs can't see.
How can we build effective multi-agent systems with vision capabilities?
Building multimodal models from scratch is expensive. Training joint vision-language architectures requires massive compute, specialized datasets, and careful optimization.
But there's another way.
This new research introduces "Be My Eyes," a framework where vision models become literal eyes for LLMs.
The key idea: multi-agent collaboration through natural language.
Vision agents analyze images an...

---

### [RT elvis: Re Learn more about MiniMax-M2 here: https://platform.minimax.io/docs/guides/text-m2-function-call Try M2 Deep Research here: https://github...](https://x.com/omarsar0/status/1993473421955731875)

*2025-11-25 14:27*

RT elvis
Re Learn more about MiniMax-M2 here: https://platform.minimax.io/docs/guides/text-m2-function-call
Try M2 Deep Research here: https://github.com/dair-ai/m2-deep-research...

---

### [RT elvis: MiniMax-M2 is a bigger deal than I thought! Just built a deep research agent with M2 - the interleaved thinking hits different! It preserves...](https://x.com/omarsar0/status/1993343349169041493)

*2025-11-25 14:27*

RT elvis
MiniMax-M2 is a bigger deal than I thought!
Just built a deep research agent with M2 - the interleaved thinking hits different!
It preserves content blocks (thinking + text + tool_use) to reason between tool calls.
Huge for self-improving agents.
Details + repo below ↓...

---

## Twitter @ginobefun

### [产品需求欲望模型](https://x.com/hongming731/status/1993317103961784612)

*2025-11-25 13:53*

产品需求欲望模型...

---

## Twitter @meng shao

### [今天在家做清洁，突然有个想法: 我似乎更喜欢做开荒，不喜欢平时的清洁。这和我更喜欢 0-1 创业，不知道大厂的 1-100 很像啊 😂 记得家里装修完第一次开荒，家...](https://x.com/shao__meng/status/1993508142647595149)

*2025-11-26 02:32*

今天在家做清洁，突然有个想法: 我似乎更喜欢做开荒，不喜欢平时的清洁。这和我更喜欢 0-1 创业，不知道大厂的 1-100 很像啊 😂
记得家里装修完第一次开荒，家人说请人做「3人8小时 800元」，作为抠门的我，自然的揽下了这个活儿，赚了一半的零花钱 400元 😂
我一个人从早上7点做到晚上11点，中间除了快速吃饭，基本没停过，做完的感觉: 确实嘴硬低估了开荒的工作量，那种灰尘不是一层层，是一堆堆的。不过。。很爽很解压，因为是空白的，干起来非常痛快有成就感，眼看着一点点的变干净的过程，非常爽！
而平时做清洁，因为家小东西多，到处都摆满了东西甚至好多层。清洁的时候要挪开一点打扫一点，感觉大半时间都是在摆放，为清洁腾出空间。而且，前后区别不大，只是心理上觉得确实清洁过了，肉眼看上去干净了一点，不爽！
再回到我工作的选择，好像也是这样，我很喜欢 0-1 的过程，很累但很爽，顾虑很少，内耗很少，一个目标，把它做出来，推出去，干就完了！
不喜欢 1-100 的过程，需要考虑的太多，人太多，人带来的事情之外的内耗太多，最后往往大家关注的点会失焦，从把事情做好，虚到每个人绩效里的证明，或者叫功绩。...

---

### [打造优秀 ChatGPT 应用的官方指南 OpenAI 开发者博客，针对开发者、产品经理和设计师，提供了一份实用指南，教你如何构建出色的 ChatGPT 应用。这些应用不是简单...](https://x.com/shao__meng/status/1993489407564038191)

*2025-11-26 01:18*

打造优秀 ChatGPT 应用的官方指南
OpenAI 开发者博客，针对开发者、产品经理和设计师，提供了一份实用指南，教你如何构建出色的 ChatGPT 应用。这些应用不是简单地将现有产品移植到聊天界面，而是将产品的核心优势转化为聊天中的特定能力，帮助模型在对话中更智能地 “知”（获取信息）、“做”（执行行动）和“秀”（呈现可视化）。
优秀的应用应保持精简、专注，避免复杂导航，转而设计成模型可轻松调用的“工具包”。
引言：从产品到对话能力的转变
开篇指出，ChatGPT 应用本质上是嵌入对话的工具集，能在用户互动中被模型调用，提供上下文、执行操作或生成可视化输出。它不是完整产品的复制，而是针对聊天场景的“能力注入”。例如，别试图把整个电商平台塞进聊天，而应聚焦于“实时查库存”这样的具体功能。文章建议开发者参考 Apps SDK 快速入门和文档，从用例选择入手，确保应用真正提升对话价值。
核心原则：价值的三大支柱
定义优秀应用的标准：它必须通过以下三种方式为模型“赋能”，否则就只是基线模型的浅层包装。每个原则都配以实际场景，帮助开发者快速评估创意。
· “知”：扩展模型的“眼睛和耳朵”
...

---

### [OCR Arena：AI 文档处理模型的实战竞技场 OCR 和 VLM 的实际表现如何，在官方 benchmark 之外，应该有更直观实际的对比，OCR Arena 就是一个专为测试真实文档设...](https://x.com/shao__meng/status/1993483339748327925)

*2025-11-26 00:53*

OCR Arena：AI 文档处理模型的实战竞技场
OCR 和 VLM 的实际表现如何，在官方 benchmark 之外，应该有更直观实际的对比，OCR Arena 就是一个专为测试真实文档设计的互动 playground，帮助开发者直观比较不同模型的表现，支持与 Gemini 3、DeepSeek-OCR、GPT-5 等 10 多个流行模型的面对面的比较。
平台亮点
· 侧边比较：实时上传文档，生成视觉差异图（visual diff），便于检查格式错误、表格完整性和提取精度。
· 多样支持：适用于结构化文件、表格、手写体和扫描图像，覆盖智能体在自动化工作流中的常见需求。
· 透明排行：公共 leaderboard 基于用户测试，提供无偏见的模型排名。
· 实际价值：Sumanth 指出，这比静态基准更可靠，因为真实文档往往“乱七八糟”，测试能揭示模型在边缘场景下的鲁棒性。
在线对比
https://www.ocrarena.ai/battle
Sumanth: I just put DeepSeek-OCR and Gemini 3 in an OCR battle!
OCR Are...

---

### [如何编写优秀的 agents. md：来自 2500+ 代码库的经验总结 核心理念 传统的 "你是一个有用的编程助手" 这类模糊指令并不有效，真正起作用的是具体的角色定义，例...](https://x.com/shao__meng/status/1993481050908246251)

*2025-11-26 00:44*

如何编写优秀的 agents. md：来自 2500+ 代码库的经验总结
核心理念
传统的 "你是一个有用的编程助手" 这类模糊指令并不有效，真正起作用的是具体的角色定义，例如明确说明"你是一位测试工程师，专门为 React 组件编写测试，遵循特定示例，且绝不修改源代码"。
agents. md 文件的作用是定义智能体的完整工作手册：角色定位、技术栈知识、项目文件结构、工作流程、可执行命令、代码风格示例，以及最重要的——明确的操作边界。
五个关键要素
通过分析发现，成功的 agents. md 文件普遍遵循以下实践：
1. 命令前置
将可执行命令放在文件前部，包含完整的命令参数和选项，例如 npm test、pytest -v，而不仅仅是工具名称。
2. 用代码示例代替文字说明
一个真实的代码片段比三段描述性文字更有效。直接展示期望的输出样式。
3. 设定清晰边界
明确告知 AI 哪些内容绝对不能触碰，如敏感信息、vendor 目录、生产配置等。"永远不要提交密钥"是最常见的有效约束。
4. 具体说明技术栈
应该写"React 18 + TypeScript，使用 Vite 和 Tai...

---

### [这段系统指令让 Gemini 3 Pro 智能体性能提升 5% 来自 @_philschmid 的分享，一个针对 Gemini 3 Pro 模型的系统指令模板。这个模板通过融入后训练最佳实践，帮助...](https://x.com/shao__meng/status/1993476888174772702)

*2025-11-26 00:28*

这段系统指令让 Gemini 3 Pro 智能体性能提升 5%
来自 @_philschmid 的分享，一个针对 Gemini 3 Pro 模型的系统指令模板。这个模板通过融入后训练最佳实践，帮助智能体在多步骤工作流中提升可靠性，并在多个智能体基准测试上实现了约 5% 的性能提升。这项改进源于与 Google DeepMind 后训练研究团队的合作，并已整合进官方文档。
Gemini 模型天生具备强大推理能力，但复杂智能体任务需要显式指令来引导模型的规划与执行行为。这些指令能强制模型采用特定策略，例如在遇到问题时保持持久性、进行风险评估，或主动规划步骤，从而减少随机错误并提高任务完成率。
指令模板的核心内容与逻辑
提供的系统指令是一个结构化的框架，旨在让模型在响应前系统性地“思考”并规划。模板以“你是一个非常强大的推理者和规划者”开头，强调主动性，然后列出 9 条关键指导原则。这些原则形成一个闭环流程，确保智能体从规划到执行都严谨可靠。
1. 逻辑依赖与约束分析：在采取任何行动（工具调用或用户响应）前，评估行动是否符合政策规则、操作顺序、前置条件和用户偏好。优先解决冲突，例如重新排序用...

---

### [FLUX 2 重磅发布：前沿视觉智能的突破 Black Forest Labs 这次发布了四个版本： · FLUX 2 [pro]：最高品质版本，通过 API 提供，速度快、成本低，在质量和速度...](https://x.com/shao__meng/status/1993470282443767867)

*2025-11-26 00:02*

FLUX 2 重磅发布：前沿视觉智能的突破
Black Forest Labs 这次发布了四个版本：
· FLUX 2 [pro]：最高品质版本，通过 API 提供，速度快、成本低，在质量和速度间实现了完美平衡。
· FLUX 2 [flex]：开放参数控制版本，开发者可以调节步数和引导系数，在质量、提示词遵循度和速度间自由权衡。
· FLUX 2 [dev]：32B 参数的开放权重模型，目前最强大的开放图像生成和编辑模型，可在单张 RTX 4090 显卡上本地运行。
· FLUX 2 [klein]（即将推出）：Apache 2.0 开源模型，从基础模型蒸馏而来，更轻量但保持强大能力。
核心创新点
1. 多参考图像支持FLUX 2 可以同时参考多达 10 张图像，在保持角色、产品或风格一致性方面达到业界最佳水平。这对品牌设计、角色开发等场景意义重大。
2. 极致的真实感与细节模型在光照、纹理和空间逻辑上有显著提升，适合产品摄影、可视化和类摄影应用场景。
3. 文字渲染能力复杂的排版、信息图表、表情包和界面原型中的精细文字现在可以在生产环境中可靠运行。这解决了 AI 图像生成中长期存在...

---

### [Ilya Sutskever – 我们正从「规模化时代」转向「研究时代」 @ilyasut 和 @dwarkesh_sp 的访谈终于来了！这位神秘的 @ssi 创始人，前 OpenAI 首席科学家，在离开...](https://x.com/shao__meng/status/1993464340293599621)

*2025-11-25 23:38*

Ilya Sutskever – 我们正从「规模化时代」转向「研究时代」
@ilyasut 和 @dwarkesh_sp 的访谈终于来了！这位神秘的 @ssi 创始人，前 OpenAI 首席科学家，在离开 OpenAI 后最完整的一次公开访谈，带来了哪些最新观点，咱们一起看看 👁
1. 规模化时代已经结束（The age of scaling is over）
· 2020-2025年是“规模化时代”（scaling era），靠堆算力+数据+预训练就能稳定变强。
· 现在边际回报急剧下降，单纯100倍算力不会带来质变。
· 未来5-10年的突破将重新依赖“研究与创新”，而不是工程堆料。
· Ilya 明确预测：2025年之后，我们回到2012-2020年的“研究时代”，只是这次大家手里有更大的算力。
2. 当前模型的“锯齿状”能力与真实世界表现脱节的根本原因
· 模型在基准测试上超强，但在真实任务中反复引入新bug、循环修复。
· Ilya 给出的解释：
· RL 阶段过度针对 evals 优化（人类研究员的“奖励黑客”），导致过度特化。
· 类似“只练了1万小时竞技编程的学生”：技...

---

### [Gemini 3.0 Pro 和 Claude Opus 4.5 生成 UI 的能力继续升级，前端还有活路吗 😂 开玩笑 😄，AI 模型生成 UI 这么牛，对人很友好，可是它们生成的 UI 对 AI ...](https://x.com/shao__meng/status/1993292461083590975)

*2025-11-25 12:15*

Gemini 3.0 Pro 和 Claude Opus 4.5 生成 UI 的能力继续升级，前端还有活路吗 😂
开玩笑 😄，AI 模型生成 UI 这么牛，对人很友好，可是它们生成的 UI 对 AI Agent 友好吗？
来自牛津大学、新加坡国立大学和微软的最新研究「AUI」，就是在探索如何利用 Computer-Use Agents (CUA) 和编码语言模型来自动化生成和优化 GUI，使界面更适合智能体而非人类的使用。
项目背景与动机
传统 GUI 主要为人类优化，强调美观、易用性和视觉吸引力（如动画和彩色布局），这导致 CUA 在操作时必须模仿人类行为，增加了复杂性和低效性。随着编程语言模型在自动生成功能性网站方面的进步，AUI 项目提出一个关键问题：能否让 CUA 作为“评判者”协助 Coder 自动设计 GUI？这种协作旨在创建“智能体原生”的界面，优先考虑任务执行效率而非人类审美。通过智能体的反馈，项目希望实现更可靠、更高效的数字环境自动化，推动智能体从被动适应向主动塑造环境的转变。
核心贡献
1. AUI-Gym 基准测试平台：这是一个专为自动 GUI 开发和测试设计的基...

---

### [自从登记失业后，最近经常收到各种市区级招聘会的短信，感谢关心 👀 我猜我在劳保局数据库中的画像: 中年、失业、被裁员、三个月没找到工作 (找工作困难户) �...](https://x.com/shao__meng/status/1993277915333902717)

*2025-11-25 11:17*

自从登记失业后，最近经常收到各种市区级招聘会的短信，感谢关心 👀
我猜我在劳保局数据库中的画像: 中年、失业、被裁员、三个月没找到工作 (找工作困难户) 😂
潜台词: 别舔着脸领失业金了，赶紧找工作啊，短信都发成这样了，动起来啊 🤗...

---

### [HunyuanOCR：腾讯开源的端到端 OCR 视觉语言模型 HunyuanOCR 参数规模仅 1B，却在多项 OCR 基准测试中达到了领先水平。它基于原生多模态架构，专为 OCR 任务优化...](https://x.com/shao__meng/status/1993265154801516551)

*2025-11-25 10:27*

HunyuanOCR：腾讯开源的端到端 OCR 视觉语言模型
HunyuanOCR 参数规模仅 1B，却在多项 OCR 基准测试中达到了领先水平。它基于原生多模态架构，专为 OCR 任务优化，适用于文本检测、文档解析、信息提取、视觉问答和文本图像翻译等场景。模型在 ICDAR 2025 DIMT 挑战赛（小模型轨道）中获得第一，并在 OCRBench、OmniDocBench 和 DoTA 等基准上超越了许多更大规模的模型，如 Qwen3-VL-4B 和 MinerU2.5。
核心特性和架构
HunyuanOCR 采用纯端到端视觉语言模型设计，避免了传统 OCR 系统中的多模块级联，从而减少了错误传播和维护成本。其架构包括三个主要组件：
· 原生分辨率视觉编码器（Hunyuan-ViT）：基于 SigLIP-v2-400M 预训练模型，参数约 0.4B，支持任意输入分辨率。通过自适应分块机制保留图像原生纵横比，擅长处理长文档、极端比例图像和低质量扫描件。
· 自适应 MLP 连接器：作为视觉与语言领域的桥梁，进行空间维度的内容压缩，减少视觉 token 序列长度，同时保留关键语义信息，...

---

### [RT meng shao: [开源推荐] Acontext：智能体上下文数据平台 @memobase_io 团队最新项目，把智能体的交互、经验和任务集中存储在一个地方，帮助开发者简化上下文...](https://x.com/shao__meng/status/1993477812721009120)

*2025-11-25 09:54*

RT meng shao
[开源推荐] Acontext：智能体上下文数据平台
@memobase_io 团队最新项目，把智能体的交互、经验和任务集中存储在一个地方，帮助开发者简化上下文工程，并显著提升智能体的性能和可靠性。通过自动观察任务执行、提取 SOP，Acontext 让智能体能够从过去的学习中迭代改进，避免重复劳动，实现更稳定的长期表现。
核心功能
· 上下文存储：支持多模态会话，包括文本、图像等内容，以及智能体生成的工件（如文件、报告），通过 Disk 模块持久化保存。
· 任务观察：后台“任务智能体”自动追踪任务进度、用户反馈和成功率，实时记录偏好和瓶颈。
· 自学习机制：从完成的任务中提炼 SOP，存入类似 Notion 的 Space 知识库，便于后续检索和复用。
· 仪表盘监控：本地 Web 界面可视化显示消息流、任务状态、工件和已学技能，支持技能的文件夹式组织。
· 多提供商兼容：无缝集成 OpenAI、Anthropic 等 SDK，支持 Python 和 TypeScript 客户端。
工作原理
Acontext 的流程简洁高效：用户与智能体交互时，会话数据实...

---

### [[开源推荐] Acontext：智能体上下文数据平台 @memobase_io 团队最新项目，把智能体的交互、经验和任务集中存储在一个地方，帮助开发者简化上下文工程，并显著提...](https://x.com/shao__meng/status/1993256873425092677)

*2025-11-25 09:54*

[开源推荐] Acontext：智能体上下文数据平台
@memobase_io 团队最新项目，把智能体的交互、经验和任务集中存储在一个地方，帮助开发者简化上下文工程，并显著提升智能体的性能和可靠性。通过自动观察任务执行、提取 SOP，Acontext 让智能体能够从过去的学习中迭代改进，避免重复劳动，实现更稳定的长期表现。
核心功能
· 上下文存储：支持多模态会话，包括文本、图像等内容，以及智能体生成的工件（如文件、报告），通过 Disk 模块持久化保存。
· 任务观察：后台“任务智能体”自动追踪任务进度、用户反馈和成功率，实时记录偏好和瓶颈。
· 自学习机制：从完成的任务中提炼 SOP，存入类似 Notion 的 Space 知识库，便于后续检索和复用。
· 仪表盘监控：本地 Web 界面可视化显示消息流、任务状态、工件和已学技能，支持技能的文件夹式组织。
· 多提供商兼容：无缝集成 OpenAI、Anthropic 等 SDK，支持 Python 和 TypeScript 客户端。
工作原理
Acontext 的流程简洁高效：用户与智能体交互时，会话数据实时流入 Sessions ...

---

### [Claude Opus 4.5 发布，本来软件工程能力确实是最强，也是首个评测超过 80 分的，不过 Anthropic 官方这张图还是很有争议。 可以理解为了突出顶端数据差异，有意...](https://x.com/shao__meng/status/1993212197716344907)

*2025-11-25 06:56*

Claude Opus 4.5 发布，本来软件工程能力确实是最强，也是首个评测超过 80 分的，不过 Anthropic 官方这张图还是很有争议。
可以理解为了突出顶端数据差异，有意折叠了 0-70 的部分，仔细看也有折叠的标记。
不过从数据可视化展示的客观性来看，还是不可取的行为，哪怕是用自家 Sonnet 4.5 来评价，问题也是相当明显的。...

---

## Twitter @nazha

### [#分享 最近写代码有点小焦虑，全程没有太大参与感，LLM 代码抽象的能力和准确性比半年前要提高很多。我现在已经辩不过它了。 以前我还可以把运行的终端错误给它...](https://x.com/xiaokedada/status/1993303677994779061)

*2025-11-25 13:00*

#分享 最近写代码有点小焦虑，全程没有太大参与感，LLM 代码抽象的能力和准确性比半年前要提高很多。我现在已经辩不过它了。
以前我还可以把运行的终端错误给它，然后说：看看看，这里又错了。现在只是一味地 Accept All，然后想：就这样上生成真的没问题吗？...

---

## Twitter @shing

### [RT 0xFunky: [Vibe Coding 實戰演示] 昨天看到wei神公佈Read only的API就想說來玩一下Vibe Coding，寫出了一個過去wei神的歷史交易數據紀錄平台，平台記錄著wei...](https://x.com/shing19_eth/status/1993329777655398919)

*2025-11-25 14:08*

RT 0xFunky
[Vibe Coding 實戰演示]
昨天看到wei神公佈Read only的API就想說來玩一下Vibe Coding，寫出了一個過去wei神的歷史交易數據紀錄平台，平台記錄著wei神過去交易資訊，然後搭配Chart的K棒來做交易Mark參考，記錄一下整個Vibe過程，順便教學一下我都怎麼 Vibe Coding 一些想法。
我沒有把平台部屬起來，直接開源放到了Github上面，所有歷史交易數據包含order還有trade還有帳戶history的csv資料也都放到雲端開放大家下載，留言都有連結。
整個Vibe過程大概花了半天，中間經歷了使用Gemini 3還有Opus 4.5，大致過程如下:
1⃣一開始使用Antigravity+Gemini3，我直接把wei神的貼文複製貼上去並加了這個prompt
"這是一個交易員公開了他的read only api，請幫我分析內文這是哪一家cex的api並且把他過去的歷史交易資訊全部抓下來存成csv"
接著他直接分析內文認為是bitmex的api，但他還是寫了一個script測試是幣安還是bitmex，確認是bitmex後就...

---

### [还不上也不会有国家敢来催债😂](https://x.com/shing19_eth/status/1993285921752727926)

*2025-11-25 11:49*

还不上也不会有国家敢来催债😂...

---

### [GPT-3.5 出来的时候我以为到头了 GPT-4 的时候我以为到头了 Sonnet 3.5的时候我以为到头了 DeepSeek R1的时候我以为到头了 Gemini 2.5 的时候我以为到头了 Sonne...](https://x.com/shing19_eth/status/1993242785634566160)

*2025-11-25 08:58*

GPT-3.5 出来的时候我以为到头了
GPT-4 的时候我以为到头了
Sonnet 3.5的时候我以为到头了
DeepSeek R1的时候我以为到头了
Gemini 2.5 的时候我以为到头了
Sonnet 3.7的时候我以为到头了
GPT-5 的时候我以为到头了
Gemini 3 我觉得终于是个头吧
现在Opus 4.5，请问可以梭哈了吗？
有没有懂王给我唠唠...

---

### [是的，迭代快很重要，因为用户端需求太diverse且不可预测、穷尽。agent想要能够随着业务快速迭代，有基于eval的自动化体系很必要](https://x.com/shing19_eth/status/1993229990511755592)

*2025-11-25 08:07*

是的，迭代快很重要，因为用户端需求太diverse且不可预测、穷尽。agent想要能够随着业务快速迭代，有基于eval的自动化体系很必要
yan5xu: 和我的开发感受非常接近
1. LLM 本质还是一个API，除了做一层抽象把各家接口进行统一（openrouter），没有其他任何抽象的需要；
2. 缓存不太认同，隐式缓存无脑，也很好用；
3. think tool 是所有做 agent 都会用的高阶技巧，可以看看 anthropic 的 think tool 博客。我打算专门写一篇文章来讨论；
4....

---

### [antigravity的plan review太舒服了，非常reasonable的设计，定有高手指点](https://x.com/shing19_eth/status/1993172839143551458)

*2025-11-25 04:20*

antigravity的plan review太舒服了，非常reasonable的设计，定有高手指点...

---

### [RT 九原客: AIStudio 这种在线创建 App的功能之前觉得很不实用，开发生产App肯定得用本地IDE/CLI。 今天突然发现做一些演示app好用，比如要授课，需要构思如何演...](https://x.com/shing19_eth/status/1993170163752140893)

*2025-11-25 03:51*

RT 九原客
AIStudio 这种在线创建 App的功能之前觉得很不实用，开发生产App肯定得用本地IDE/CLI。
今天突然发现做一些演示app好用，比如要授课，需要构思如何演示 Claude Code 的 Skill 机制，让它生成一个交互式的 App，非常的直观。...

---

### [改了policy位置后，可以用上antigravity咯](https://x.com/shing19_eth/status/1993163762657116607)

*2025-11-25 03:44*

改了policy位置后，可以用上antigravity咯...

---

## Twitter @uncle-lu

### [终于能正常演示Splay了。狠狠迫使Gemini：彻底重构了 src/services/langchainService.ts，从之前的 StructuredOutputParser (基于 Prompt Engineering 的 JSON ...](https://x.com/GemstoneNicole/status/1993203175801897200)

*2025-11-25 06:20*

终于能正常演示Splay了。狠狠迫使Gemini：彻底重构了 src/services/langchainService.ts，从之前的 StructuredOutputParser (基于
Prompt Engineering 的 JSON 生成) 迁移到了 LangChain 更现代、更健壮的 .withStructuredOutput()
方法 (基于 Gemini 的 Native Tool Calling/Function Calling)。
uncle-lu: VibeCoding了一个上课用的算法动画生成工具。借鉴的ChatWise的思路，让Gemini生成一个React组件。用Gemini3和GLM一起写的项目，不得不说，LLM还是有点菜，得先吧技术架构写清楚，然后把每个工具的文档下载下来，读一部分写一部分。才能保证写的没啥问题。...

---

### [VibeCoding了一个上课用的算法动画生成工具。借鉴的ChatWise的思路，让Gemini生成一个React组件。用Gemini3和GLM一起写的项目，不得不说，LLM还是有点菜，得先吧...](https://x.com/GemstoneNicole/status/1993198115231613006)

*2025-11-25 06:00*

VibeCoding了一个上课用的算法动画生成工具。借鉴的ChatWise的思路，让Gemini生成一个React组件。用Gemini3和GLM一起写的项目，不得不说，LLM还是有点菜，得先吧技术架构写清楚，然后把每个工具的文档下载下来，读一部分写一部分。才能保证写的没啥问题。...

---

## Twitter @wwwgoubuli

### [RT Shelly: 我今天才跟我们的开发说: 非技术人员 vibe 出来的，你就真的当前端体验用，深刻理解业务人员想要什么，从功能，到体验到认知，跑演示或者自己用的就...](https://x.com/wwwgoubuli/status/1993350368991011116)

*2025-11-25 15:30*

RT Shelly
我今天才跟我们的开发说:
非技术人员 vibe 出来的，你就真的当前端体验用，深刻理解业务人员想要什么，从功能，到体验到认知，跑演示或者自己用的就好啊，不要当系统设计。
少个分号: AI时代的程序员完全不需要焦虑。
当熊来了你不需要比熊跑得快，
只需要跑的比其他人快。
程序员联合AI去绞杀其他行业就行。...

---

### [我八百年不上微博，上去了发现那么多好玩的东西。 以后当个搬运博主得了。](https://x.com/wwwgoubuli/status/1993306872599003580)

*2025-11-25 13:12*

我八百年不上微博，上去了发现那么多好玩的东西。
以后当个搬运博主得了。...

---

### [ampcode free mode](https://x.com/wwwgoubuli/status/1993290579443425379)

*2025-11-25 12:08*

ampcode free mode
ZEN: 🤔...

---

### [RT 阑夕: 晚点LatePost昨天发了一篇Kimi和MiniMax的近况报道，感觉现在也只有这家媒体还在关注「AI六小龙」了，自从巨头下场开始规模化投放之后，独立AI公司的生...](https://x.com/wwwgoubuli/status/1993282974239146095)

*2025-11-25 09:22*

RT 阑夕
晚点LatePost昨天发了一篇Kimi和MiniMax的近况报道，感觉现在也只有这家媒体还在关注「AI六小龙」了，自从巨头下场开始规模化投放之后，独立AI公司的生存空间已被蚕食殆尽了，月之暗面和MiniMax是其中尚且存有活路的两家，确实值得多写写。
简单总结如下：
- 月之暗面和MiniMax很像，都在全尺寸路线上摇摆过，Kimi成功之后，月之暗面尝试过复现Sora的视频效果，但一直没有达到预期，出海产品也相继关停，MiniMax想学字节做App工厂，推了Talkie、星野、海螺等2C产品，却不具备字节的工业化获客体系，于是这两家公司都承担了很高的试错成本；
- 去年是中国大模型行业士气最低的时期，投资机构失去耐心，要求看到DAU的直观指标，倒逼创业公司进入了和豆包这种无限弹药的产品拼消耗的赛道，「打不过，但不能停」成了普遍心态，而投资人之间的议程也变成了卖股份，信心层面的亏空巨大；
- MiniMax本来并不想主打视频模型，然而海螺生成视频的能力在海外爆火，反过来影响了管理层的注意力，开始变得「既要又要」——既要增长，又不要色情生成场景的流量——结果受困于审核力度的调...

---

### [RT Josh: 想不到吧，python 标准库 zoneinfo 会尝试从你安装的第三方库 tzdata 中加载时区信息](https://x.com/wwwgoubuli/status/1993278117751013884)

*2025-11-25 09:14*

RT Josh
想不到吧，python 标准库 zoneinfo 会尝试从你安装的第三方库 tzdata 中加载时区信息...

---

### [RT Dash: 下午和 TapTap 的同事们开会了解明年新游戏的 pipeline，发现明年的 S 级产品里，已经有差不多 90% 是 PC/手机的双端互通产品了，剩下的是纯 PC 游戏，...](https://x.com/wwwgoubuli/status/1993354681285066979)

*2025-11-25 09:03*

RT Dash
下午和 TapTap 的同事们开会了解明年新游戏的 pipeline，发现明年的 S 级产品里，已经有差不多 90% 是 PC/手机的双端互通产品了，剩下的是纯 PC 游戏，纯手游的 S 级产品已经几乎绝迹了…...

---

### [以前不混前端圈子，只是听说过，但都不知道有神光这么一位神人。](https://x.com/wwwgoubuli/status/1993201224691388601)

*2025-11-25 06:12*

以前不混前端圈子，只是听说过，但都不知道有神光这么一位神人。...

---

### [每次看到这些大家最近爱生成的图的时候，我都有一种脑子不够用了的感觉。 今天突然知道为什么了。 不时图形和文字的AI感的问题，而是内容的呈现问题。 不管这个...](https://x.com/wwwgoubuli/status/1993199744135708785)

*2025-11-25 06:07*

每次看到这些大家最近爱生成的图的时候，我都有一种脑子不够用了的感觉。
今天突然知道为什么了。
不时图形和文字的AI感的问题，而是内容的呈现问题。
不管这个图形什么风格，多么个性化，内容分析的多有条例，本质上这种展现形式就像让你阅读一个 interface / schema / json / toml 一样。
一个有一大堆信息的东西扑面而来，一下子就看的脑瓜子嗡嗡的。
事实上我引用的这张图还算是好的，画面虽然满，也没有合适的留白（说起来我发现最近看到的图大家都不知道要让AI做留白），内容也没爆炸，但还是一样看过去，多，杂。
这已经算是信息量少的了，我真的无法理解那种更大幅，文字和要素更多的图，除了收藏一下，其他还能有什么用。
宝玉: 🍌 nano banana pro prompt
--- Prompt ---
Please create an infographic based on the input content, highlighting key themes and essential points:
- Simplify information, emphasizing k...

---

### [害怕😨](https://x.com/wwwgoubuli/status/1993198591180259689)

*2025-11-25 06:02*

害怕😨...

---

## Twitter @凡人小北

### [最近玩疯了。 这两周基本是在 Gemini 3 和 Nano Banana Pro 之间来回折腾，跟被点满了生图天赋一样，天天生成到天亮。 模型强大带来的效果丝滑，很容易被这种爽...](https://x.com/frxiaobei/status/1993358220044517856)

*2025-11-25 16:36*

最近玩疯了。
这两周基本是在 Gemini 3 和 Nano Banana Pro 之间来回折腾，跟被点满了生图天赋一样，天天生成到天亮。
模型强大带来的效果丝滑，很容易被这种爽感裹挟进去。
但可能正因为玩得太嗨，反倒让我注意到一个反差：
大家好像都把 agent 暂时忘了。
不知道有多少人跟我一样，时间线被更强的模型和更丝滑的生图刷得密不透风。
agent 那一套跑流程的讨论从时间线里消失了。
这很值得警惕。最近在其他平台在看一些项目、也跟几家公司聊，能感觉 agent 在悄悄蓬勃起来。
不吵不闹，也没有那种炸裂发布会。但能看到它开始钻进各种真实业务里。
以前要人盯着的小任务，它们有的已经开始自己跑了。
模型升级确实很爽，但 agent 的演化到了没声量但稳稳前进的时刻。
警醒下自己，
玩模型当然好爽，但如果一直停在好玩，很容易忽略掉一个事实：
最后决定业务价值的，往往是那些能把模型用起来的流程和系统。
所以也给自己按了个暂停键：
收敛一下，该回到 agent 这条线索上继续深挖了。
有时候，冷门不是真的没人做，只是热闹把声音盖住了。
而真正值得跟的方向，往往就是这种安静并且一步一个...

---

### [](https://x.com/frxiaobei/status/1993261393660067892)

*2025-11-25 10:12*

---

### [Android 官方亲自下场了，强行把 AirDrop 拉进来做跨阵营快传。 我能想象到的最直观的体验是跟iPhone互传照片的时候再也不用受折磨，特别是我这种双持党。 方案...](https://x.com/frxiaobei/status/1993253353326100482)

*2025-11-25 09:40*

Android 官方亲自下场了，强行把 AirDrop 拉进来做跨阵营快传。
我能想象到的最直观的体验是跟iPhone互传照片的时候再也不用受折磨，特别是我这种双持党。
方案也很直接，Pixel 10 上 Quick Share 跟 AirDrop 硬插了一条。非官方公共通道。
这个比国内几家公司强行兼容的垃圾方案高明了好多个档次。
个人认为这是好事儿，Android开始对这个封闭生态正面进攻，
一旦跨系统文件互传这种高频刚需被打通，
以后换机决策的时候被困在圈子里的锁定感就能小很多。
对只有苹果全家桶才顺滑的绑定会有很大的蚕食。
好了，Apple 怎么接这个局，Cook明年退休，明年的日子怕是不太好过。
Android: Sharing moments shouldn’t depend on the phone you have. Starting today with the Pixel 10 family, Quick Share now works with AirDrop, making secure file transfers between Android phones...

---

### [Gemini 生成图片不清晰？是导出方法错了，@dotey 的方法扩散给更多人。 原来如此，我一直用的是图片点击大图后 cmd+c，只有100 多 k。](https://x.com/frxiaobei/status/1993189744894001313)

*2025-11-25 05:27*

Gemini 生成图片不清晰？是导出方法错了，@dotey 的方法扩散给更多人。
原来如此，我一直用的是图片点击大图后 cmd+c，只有100 多 k。
宝玉: @rootnick 不要直接复制图片，清晰度很差，要下载...

---

### [如果你问一个程序员，AI Coding 到底改变了什么。 他会告诉你： 模型写的代码不够稳、业务太复杂、工程化做不到、调库也不准、PR 质量不行。 但你问他： 你最近...](https://x.com/frxiaobei/status/1993185342162452524)

*2025-11-25 05:09*

如果你问一个程序员，AI Coding 到底改变了什么。
他会告诉你：
模型写的代码不够稳、业务太复杂、工程化做不到、调库也不准、PR 质量不行。
但你问他：
你最近的工作到底做了什么？
他能从架构演进讲到历史包袱，从系统约束讲到隐性知识，滔滔不绝一个小时。
每句话都在证明：自己在这个岗位上仍然不可替代。
这，就是摆在每一个程序员面前最真实的世界。
我们不是不想拥抱未来。
只是很难接受：
自己花了十几二十年打磨出来的经验和技艺，
正在被某些新技术以肉眼可见的速度一点点拉平。
这不是恐惧，这是人之常情。
Li Xiangyu 香鱼🐬: 如果你问一个结构生物学家，alphafold到底改变了什么。
他会告诉你alphafold没法解大蛋白复合物，真核生物蛋白质的结构预测不准确。
但你问他他的工作做了什么
他可以滔滔不绝一个小时，来证明自己的不可替代性。
这就是摆在每一个生物学家面前最真实的世界。
我们不是不愿意拥抱世界。...

---

### [本来大家都以为 AI 的剧本已经写死了： 模型看 OpenAI，芯片看英伟达。 结果 Gemini 3 一出，剧情突然就反转了。 Google 除了大秀模型，还把真正的杀招摊开摆在...](https://x.com/frxiaobei/status/1993169849804071345)

*2025-11-25 04:08*

本来大家都以为 AI 的剧本已经写死了：
模型看 OpenAI，芯片看英伟达。
结果 Gemini 3 一出，剧情突然就反转了。
Google 除了大秀模型，还把真正的杀招摊开摆在桌上，TPU 不止在云里跑，现在要进 Meta 的机房。
市场瞬间整明白了：Google 想建立的一条完整的谷歌链开始成型了。
听懂的也包括Nvidia，
谷歌刚给 Anthropic 扔了 100 万片 TPU，
黄仁勋立刻回手几十亿投资，把对方再锁回 GPU 阵营。
动作跟被谁刺了一刀一样麻利。
划重点，
这是第一次有人证明除了 GPU，TPU 也能撑起最强模型。
而且还便宜省电。
以后英伟达的日子就不会再像去年那么舒服了。
故事还没完，但很明显：
Google 掺合进来后 已经开始改写 AI 的供应链叙事，
英伟达也得开始算一笔从没算过的账。
看好 Google。...

---

## Twitter @向阳乔木

### [AI 与芯片结合，可能出现的新应用场景 1. 具身智能 现在AI都是在屏幕里，未来AI要走进物理世界。 如机器人、无人机、自动驾驶。 芯片必须能实时处理视觉、决策、...](https://x.com/vista8/status/1993484284469166132)

*2025-11-26 00:57*

AI 与芯片结合，可能出现的新应用场景
1. 具身智能
现在AI都是在屏幕里，未来AI要走进物理世界。
如机器人、无人机、自动驾驶。
芯片必须能实时处理视觉、决策、控制，且功耗要很小。
比如，特斯拉的Optimus机器人，还有Figure、1X这些人形机器人公司，都在自研AI芯片。
通用芯片满足不了"边走、边想、边做"这种实时性要求。
未来3-5年，如果具身智能芯片成熟了。
可能会看到AI保姆、AI工人、AI快递员，这是万亿级的市场。
2. 端侧多模态，手机、汽车、眼镜都能跑大模型。
现在大模型多数在云端。
未来会下沉到我们的手机、汽车、AR眼镜里。
要求芯片能在几瓦功耗下，同时处理文字、图像、语音、视频。
高通、联发科、华为都在押注这个方向。
这个场景如果实现，会催生新一代的智能硬件。
就像当年iPhone开启智能手机时代一样。
3. AI原生科学计算
以前超算是用来算天气、算核爆炸。
未来 AI 芯片会成为科学计算的主力。
很多科学问题，用AI的方式算比传统方法快几千倍。
比如 AlphaFold 预测蛋白质结构，就是用AI芯片算出来的。
未来如有专门针对科学计算优化的AI芯片。
...

---

### [AI在重新定义芯片该长什么样。 芯片也在决定AI能走多远。 有三个趋势： 1. 从通用走向专用。 以前大家都用通用GPU跑AI。 但现在会发现，针对大模型推理、训练、...](https://x.com/vista8/status/1993482409954902473)

*2025-11-26 00:50*

AI在重新定义芯片该长什么样。
芯片也在决定AI能走多远。
有三个趋势：
1. 从通用走向专用。
以前大家都用通用GPU跑AI。
但现在会发现，针对大模型推理、训练、端侧部署。
芯片的设计逻辑完全不一样。
未来3-5年，我觉得会出现更多专用AI芯片。
比如说，训练芯片要堆算力，推理芯片要省功耗，端侧芯片要低延迟。
英伟达现在也在分化产品线，H系列做训练，L系列做推理。
国内像壁仞、燧原这些公司，也在找差异化定位。
未来不会一家通吃，会形成 "训练有训练的王者，推理有推理的霸主，端侧有端侧的玩家" 这样的格局。
2. 存算一体突破，解决内存墙问题。
现在大模型最大的瓶颈不是算力，是数据搬运。
芯片要不停地从内存读数据、算完再写回去，这个过程太慢、太耗电。
存算一体就是把计算和存储放在一起，数据不用来回搬了。
技术如果突破，对AI的影响巨大。
清华、中科院、还有一些创业公司都在做这个方向。
未来3-5年，如果存算一体芯片能量产。
让大模型的推理成本降低一个数量级，很多现在做不了的应用到时就能做了。
3. 芯片和算法一起优化。
以前算法工程师写代码，芯片工程师做芯片，两边各干各的。
但现在很...

---

### [你可能好奇：做AI自媒体的人，到底图什么？ 图被看见。 就这么简单。 赚钱吗？ 说实话，除公众号商单，其他赚不了多少。 涨粉吗？涨粉本身没什么用。 那图什么？...](https://x.com/vista8/status/1993470272079642867)

*2025-11-26 00:02*

你可能好奇：做AI自媒体的人，到底图什么？
图被看见。
就这么简单。
赚钱吗？ 说实话，除公众号商单，其他赚不了多少。
涨粉吗？涨粉本身没什么用。
那图什么？图虚荣心。
图那种 "有人在看我写的东西" 的感觉。
图那种 "去一个城市，有网友接待我" 的感觉。
图那种 "我分享的提示词或产品，有人记得" 的感觉。
这些东西，满足了我的虚荣心。
你可能觉得：这也太肤浅了。
但我觉得：这不肤浅，这是人性。
我们都需要被看见。
我们都需要被认可。
只是方式不同。
“虚荣心”，也是一种动力。
会让人持续输出、思考，跟更多人连接。
如果没有虚荣心，可能早就不做了。
感谢看我 X 和公众号的朋友、感谢加入乔木社群的朋友。
---
最后，感谢神佬的组织 @berryxia_ai ，明天终于能见到深圳的群友了。
---
以上由 AI 创作辅助。...

---

### [如果看不懂如何安装一些开源的Github应用。 可以打开Claude Code输入： “一步步带我安装部署这个开源github项目 [ Github URL]” 后续在AI引导下，一步步操作完...](https://x.com/vista8/status/1993369051071152552)

*2025-11-25 17:19*

如果看不懂如何安装一些开源的Github应用。
可以打开Claude Code输入：
“一步步带我安装部署这个开源github项目 [ Github URL]”
后续在AI引导下，一步步操作完成。...

---

### [入住一家深圳的酒店，广东电信的WiFi上网太拉胯了。 手机wifi连上，弹出登录页面，输入手机，发送短信，没有自动获取短信。 切换到短信查看验证码，登录界面不见...](https://x.com/vista8/status/1993361555145277743)

*2025-11-25 16:50*

入住一家深圳的酒店，广东电信的WiFi上网太拉胯了。
手机wifi连上，弹出登录页面，输入手机，发送短信，没有自动获取短信。
切换到短信查看验证码，登录界面不见了，又得重头输入...
好在第二次发送的短信还有效，终于搞定。
然后，发现Mac电脑连上wifi也不弹出认证页面。
修改DNS为 8.8.8.8 ，检查关掉所有代理。
输入192.168.1.1 强制跳转认证页面，输入手机号验证码登录。
终于上网成功。...

---

### [RT 歸藏(guizang.ai): 藏师傅的相去哪儿就去哪儿相机终于发布了正式版！ 我还专门写了个官网来介绍功能，同时增加了三个渠道，保证有一个你是能用。 赶紧来试试...](https://x.com/vista8/status/1993333297087496688)

*2025-11-25 13:03*

RT 歸藏(guizang.ai)
藏师傅的相去哪儿就去哪儿相机终于发布了正式版！
我还专门写了个官网来介绍功能，同时增加了三个渠道，保证有一个你是能用。
赶紧来试试：https://bananacamera.trickle.host/
歸藏(guizang.ai): 搞了个好玩的，Nano Banana Pro 帮你生成任意位置的打卡照！
用 Gemini 3 写了个工具，只需要在地图上选点，然后上传你的人脸照片，就可以生成你在这个地方的打卡照。
会根据当前位置的天气和时间生成图片，你的衣服也会根据现在的时间以及天气去变化。
人脸一致性真的太高了，我去。...

---

### [原来通过摄像头控制电脑这么方便。 创意来自 @zarazhangrui ，今天试着用Claude Code写了一个类似的Python代码。 真的就是一段提示词，简单调1-2轮就搞定了。 提...](https://x.com/vista8/status/1993217559794221501)

*2025-11-25 07:17*

原来通过摄像头控制电脑这么方便。
创意来自 @zarazhangrui ，今天试着用Claude  Code写了一个类似的Python代码。
真的就是一段提示词，简单调1-2轮就搞定了。
提示词参考zara的分享...

---

### [Stable Diffusion背后的秘密：原来一直在去噪，不是在画图！ --- 你可能用过 Stable Diffusion。 当输入"一只猫坐在沙发上"。 然后，你看着进度条，一点一点往前...](https://x.com/vista8/status/1993205448024244266)

*2025-11-25 06:29*

Stable Diffusion背后的秘密：原来一直在去噪，不是在画图！
---
你可能用过 Stable Diffusion。
当输入"一只猫坐在沙发上"。
然后，你看着进度条，一点一点往前走。
10%... 20%... 30%...
图像慢慢从模糊变清晰。
一开始，全是噪点。
然后，隐约能看到一些形状。
再然后，能看到猫的轮廓。
最后，一张清晰的图出现了。
你有没有想过，它到底在干什么？
答案是：去噪。
它不是在"画"图。
它是在"去噪"。
一开始，给它一张纯噪声图。
就是那种电视没信号时的雪花屏。
然后，它一步一步把噪声去掉。
每去掉一点，图就清晰一点。
去了 50 步，图就清晰了。
这就是 DDPM：Denoising Diffusion Probabilistic Model。
（去噪扩散概率模型）
听起来很复杂，但核心就是两个字：去噪。
但这里有个神奇的地方：
它怎么知道该去成什么样？
我是说，同样是一堆噪声，
你可以去成猫，可以去成狗，可以去成车。
它怎么知道你要的是猫？
答案是：你告诉它的。
你输入"一只猫坐在沙发上"。
这段文字，会被变成一个向量。
然后，在每一步去...

---

### [中文没有空格，分词就是个大问题。 中文一词多义，"意思"和"意思"可能是完全不同的意思。 中文语序灵活，"我打了他"和"他被我打了"，主语都不一样。 所以，中文...](https://x.com/vista8/status/1993194867590414701)

*2025-11-25 05:47*

中文没有空格，分词就是个大问题。
中文一词多义，"意思"和"意思"可能是完全不同的意思。
中文语序灵活，"我打了他"和"他被我打了"，主语都不一样。
所以，中文太复杂，机器搞不定。
我以前也这么想。
直到我理解了 Word2Vec 是怎么工作的。
它根本不在乎语言的语法规则。
它只看一件事：这个词周围都是谁。
"苹果"周围经常是"水果""香蕉""新鲜"。
"蘋果"周围也是。
"apple"周围也是。
对 Word2Vec 来说，这三个词是一回事。
因为它们的用法一样。
中文有一词多义？没关系。
"苹果"（水果）周围是"吃""甜""新鲜"。
"苹果"（公司）周围是"手机""电脑""发布会"。
Word2Vec 会给它们不同的向量。
因为它们的上下文不一样。
中文分词难？也没关系。
Word2Vec 可以直接在字符级别上训练。
不需要分词，直接看字和字之间的关系。
甚至有研究发现，字符级别的中文词向量，效果不比分词后的差。
因为对机器来说，语言不是规则，是统计。
它不需要懂语法，它只需要看够多的数据。
看多了，它自己就知道：
哪些字经常一起出现，哪些词意思相近，哪些句子表达相似的意思。
英...

---

### [面试官问我：能用一句话解释 Word2Vec 吗？ 我当时脑子里全是"Skip-gram""CBOW""负采样"... 但我知道，这些词说出来，面试就结束了。 后来，我想明白了。 Word2V...](https://x.com/vista8/status/1993194344975860033)

*2025-11-25 05:45*

面试官问我：能用一句话解释 Word2Vec 吗？
我当时脑子里全是"Skip-gram""CBOW""负采样"...
但我知道，这些词说出来，面试就结束了。
后来，我想明白了。
Word2Vec 就是给词做定位。
就像给城市做定位。
北京和上海，都是大城市，所以它们在"城市规模"这个维度上很接近。
北京和天津，地理位置近，所以它们在"地理位置"这个维度上很接近。
Word2Vec 做的事情是一样的。
它给每个词找一个位置。
意思相近的词，位置就近。
怎么找这个位置？
看它周围都是谁。
"苹果"周围经常是"水果""香蕉""新鲜"。
"手机"周围经常是"电脑""屏幕""充电"。
所以机器知道，"苹果"应该和"香蕉"靠近，和"手机"远离。
这就是 Word2Vec。
不是教机器词典，是让机器看大量文本，自己学会每个词应该在哪里。
学完之后，你就可以算任意两个词有多像。
甚至可以做加减法：
King - Man + Woman = Queen
因为"性别"这个维度，在这个空间里是可以被分离出来的。
这是 2013 年的突破。
从那之后，机器才真的能"理解"语义。
所有现在的 NLP，都建立在...

---

### [为什么一定要做自己的产品？ 大家经常聊“睡后收入”。 但没人告诉你： 睡后收入的本质，不是钱自己会来，是你变贵了。 什么叫变贵？ 就是你做一次的东西， 可以...](https://x.com/vista8/status/1993181434341999089)

*2025-11-25 04:54*

为什么一定要做自己的产品？
大家经常聊“睡后收入”。
但没人告诉你：
睡后收入的本质，不是钱自己会来，是你变贵了。
什么叫变贵？
就是你做一次的东西，
可以卖一百次、一千次。
你写一篇文章，可以被搜索到一万次，帮助很多人。
你录一个课程，可以被购买三年。
你做一个模板，可以被下载无数遍。
你没有睡后收入，不是因为你不够努力。
是因为你做的事情，只能卖一次。
你的时间在卖，你的体力在卖，但你的成果没有在"复利"。
所以，得先想明白一件事：
现在做的，能不能脱离你的时间，自己产生价值？
如果不能，那你做得再多，也只是在用命换钱。
---
以上由 AI 生成，觉得有道理。
但要做什么产品，每个人都不一样。
需要一点路径依赖，也需要一点机缘。...

---

## Twitter @吕立青_JimmyLv (闭关ing) 2𐃏25

### [硅谷 101 几乎每一期我都有刷， 准备 http://CutFa.st 剪剪切片分享给大家～ 示例 🔗 https://cutfa.st/editor?url=https://www.youtube.com/watch?v=1pgCnlJR...](https://x.com/Jimmy_JingLv/status/1993345511911571573)

*2025-11-25 15:46*

硅谷 101 几乎每一期我都有刷，
准备 http://CutFa.st 剪剪切片分享给大家～
示例 🔗 https://cutfa.st/editor?url=https://www.youtube.com/watch?v=1pgCnlJRuxE
KK.aWSB: 推荐一个值得长期订阅的科技播客：硅谷 101。
质量强过绝大多数中文科技内容，然后你会觉得那些靠颜值和流量话题充数的视频博主都可以取关了。
避免信息茧房的最好方式，不是“看更多”，而是了解不同边界的知识。很多人每天刷美股、刷加密、刷 AI，收到的永远是同一圈资讯，久了会让认知越来越窄。...

---

## Twitter @哥飞

### [一直说要去打流感疫苗，一直忙，拖到今天终于去打了。 还是很建议大家去打的，打了之后不是说完全不会得流感，而是可以降低概率，同时万一得了也可以减轻症状，...](https://x.com/gefei55/status/1993490982663602410)

*2025-11-26 01:24*

一直说要去打流感疫苗，一直忙，拖到今天终于去打了。
还是很建议大家去打的，打了之后不是说完全不会得流感，而是可以降低概率，同时万一得了也可以减轻症状，所以好处多多。...

---

### [上周，花两千刀，相当于一万多块钱，买了个 com 域名，立项做个新产品。 估计元旦前能上线。](https://x.com/gefei55/status/1993323526372442238)

*2025-11-25 14:18*

上周，花两千刀，相当于一万多块钱，买了个 com 域名，立项做个新产品。
估计元旦前能上线。...

---

### [做出海产品，通过合理的定价，把愿意付费的人筛选出来，然后你就等着他不断充值就行。 截图这个用户，10月30日注册，3分钟后订阅了100美金的套餐，很快两三天把...](https://x.com/gefei55/status/1993323278094471399)

*2025-11-25 14:17*

做出海产品，通过合理的定价，把愿意付费的人筛选出来，然后你就等着他不断充值就行。
截图这个用户，10月30日注册，3分钟后订阅了100美金的套餐，很快两三天把积分用完了，又在11月1日充值了100刀买了一个积分包，9天后又买了个70刀的积分包，之后在19号买了200刀的积分包，25号也就是刚刚，再买了200刀的积分包。
这样算下来，一个月，他已经充值670刀了。
换算成人民币，就差不多5000块钱了。
国内要找一个月用5000的用户，只能是 B 端用户了，销售成本就要不少。
而出海，就能够找到 C 端，或者说小 B 端，愿意付这么多钱的人。...

---

### [有些人就是没见过大蛇屙屎 受哥飞“毒害”最深的，现在已经组团队开公司大干特干了，没受“毒害”的就只会扯嘴皮子，开口就是谎话连篇，没有任何证据，瞎话张口...](https://x.com/gefei55/status/1993287166445891651)

*2025-11-25 11:54*

有些人就是没见过大蛇屙屎
受哥飞“毒害”最深的，现在已经组团队开公司大干特干了，没受“毒害”的就只会扯嘴皮子，开口就是谎话连篇，没有任何证据，瞎话张口就来，满嘴喷粪。...

---

## Twitter @宝玉

### [RT Elaina: 终于来了，ChatGPT的语音通话无需再在单独界面中进行了，直接在文字对话聊天中就可以进行，减少割裂感，也是及时响应模型变得越来越快速回应时应用上...](https://x.com/dotey/status/1993436205233717298)

*2025-11-25 18:11*

RT Elaina
终于来了，ChatGPT的语音通话无需再在单独界面中进行了，直接在文字对话聊天中就可以进行，减少割裂感，也是及时响应模型变得越来越快速回应时应用上必然的改进😸
OpenAI: You can now use ChatGPT Voice right inside chat—no separate mode needed.
You can talk, watch answers appear, review earlier messages, and see visuals like images or maps in real time.
Rolling out to all users on mobile and web. Just update your app....

---

### [RT Shelly: 我今天才跟我们的开发说: 非技术人员 vibe 出来的，你就真的当前端体验用，深刻理解业务人员想要什么，从功能，到体验到认知，跑演示或者自己用的就...](https://x.com/dotey/status/1993360535224565980)

*2025-11-25 15:30*

RT Shelly
我今天才跟我们的开发说:
非技术人员 vibe 出来的，你就真的当前端体验用，深刻理解业务人员想要什么，从功能，到体验到认知，跑演示或者自己用的就好啊，不要当系统设计。
少个分号: AI时代的程序员完全不需要焦虑。
当熊来了你不需要比熊跑得快，
只需要跑的比其他人快。
程序员联合AI去绞杀其他行业就行。...

---

### [RT yousa: 我把前几天在Trae的分享整理成了文字稿 「https://yousali.com/posts/20251124-how-to-coding-with-ai/」 这篇文章写给已经在或准备在真实生产项目里...](https://x.com/dotey/status/1993457570254930172)

*2025-11-25 11:11*

RT yousa
我把前几天在Trae的分享整理成了文字稿
「https://yousali.com/posts/20251124-how-to-coding-with-ai/」
这篇文章写给已经在或准备在真实生产项目里用 AI Coding 的后端 / 全栈工程师和技术管理者。
它不会教你「按钮在哪里」「哪个 prompt 最神」，而是想在大约 15 分钟里，帮你搞清楚三件事：
哪些任务交给 AI 最「划算」；
怎么让项目本身变得更「AI 友好」，提高一次命中率；
当生成不再是瓶颈时，工程师应该如何设计验证流程，把时间花在真正值钱的地方。...

---

### [RT 汉松: 用 nano banana pro 制作哆啦 A 梦漫画，除了用下面这个方法，我发现还有个更简单的方法：让 NotebookLM 直接生成漫画版的 PPT。这里要用到NotebookLM ...](https://x.com/dotey/status/1993319965965824185)

*2025-11-25 10:05*

RT 汉松
用 nano banana pro 制作哆啦 A 梦漫画，除了用下面这个方法，我发现还有个更简单的方法：让 NotebookLM 直接生成漫画版的 PPT。这里要用到NotebookLM 生成 PPT 功能中的自定义提示词方法，prompt 是“让大雄和哆啦A梦为主人公，以漫画形式，带领读者由浅入深地学习并了解这篇文章”，具体操作可以看截图。
汉松: 一图胜千言，哆啦 A 梦学习法太强了。以后看论文和技术文章，都可以用这个方法快速了解原理。（使用方法见评论区）...

---

### [RT 阑夕: 晚点LatePost昨天发了一篇Kimi和MiniMax的近况报道，感觉现在也只有这家媒体还在关注「AI六小龙」了，自从巨头下场开始规模化投放之后，独立AI公司的生...](https://x.com/dotey/status/1993312314549059896)

*2025-11-25 09:22*

RT 阑夕
晚点LatePost昨天发了一篇Kimi和MiniMax的近况报道，感觉现在也只有这家媒体还在关注「AI六小龙」了，自从巨头下场开始规模化投放之后，独立AI公司的生存空间已被蚕食殆尽了，月之暗面和MiniMax是其中尚且存有活路的两家，确实值得多写写。
简单总结如下：
- 月之暗面和MiniMax很像，都在全尺寸路线上摇摆过，Kimi成功之后，月之暗面尝试过复现Sora的视频效果，但一直没有达到预期，出海产品也相继关停，MiniMax想学字节做App工厂，推了Talkie、星野、海螺等2C产品，却不具备字节的工业化获客体系，于是这两家公司都承担了很高的试错成本；
- 去年是中国大模型行业士气最低的时期，投资机构失去耐心，要求看到DAU的直观指标，倒逼创业公司进入了和豆包这种无限弹药的产品拼消耗的赛道，「打不过，但不能停」成了普遍心态，而投资人之间的议程也变成了卖股份，信心层面的亏空巨大；
- MiniMax本来并不想主打视频模型，然而海螺生成视频的能力在海外爆火，反过来影响了管理层的注意力，开始变得「既要又要」——既要增长，又不要色情生成场景的流量——结果受困于审核力度的调...

---

### [RT 歸藏(guizang.ai): 有的朋友可能觉得有点花哨 迭代了一下这个 Anthropic 风格的 Nano Banana Pro PPT 提示词。 现在会非常克制的使用插图元素，以及严格遵循...](https://x.com/dotey/status/1993179578567942650)

*2025-11-25 03:40*

RT 歸藏(guizang.ai)
有的朋友可能觉得有点花哨
迭代了一下这个 Anthropic 风格的 Nano Banana Pro PPT 提示词。
现在会非常克制的使用插图元素，以及严格遵循网格布局，少用圆润的卡片。
下面是迭代后的提示词👇
帮我根据下面这个文章做一套专业的的中文PPT。
先写1个PPT大纲，规划出每一页的PPT的内容。
然后将每一页的PPT内容分别扔给Nana Banana pro生成对应页面的PPT，需要确保风格一致。
PPT的具体风格应该为“Anthropic/Claude 风格”的“温暖学术人文主义”设计。
背景：使用暖米色/奶油色 (# F3F0E9) 作为纯色底色，略微高级纸张质感。
字体：标题使用优雅的衬线体（Serif），正文使用现代无衬线体（Sans-serif）。
配色：主色调为赤陶红 (# D67052) 和芥末黄 (# F0B857)，搭配深海军蓝作为点缀。避免使用霓虹色或纯黑色。
视觉元素：使用注重排版的网格布局，插图风格应为抽象的、有机的黑色手绘线条画，置于赤陶红纯色色块之上，你需要非常克制的使用插图和点缀类的插图元素，插图需要为内容...

---

## Twitter @小互

### [Claude Opus 4.5 发布后动静很小 按道理是“强得离谱”的版本 并没有引起大家的兴奋 这背后反映的是一个非常明显的行业变化： 整个AI行业已经进入“实用主义时代...](https://x.com/imxiaohu/status/1993303990097056074)

*2025-11-25 13:01*

Claude Opus 4.5 发布后动静很小
按道理是“强得离谱”的版本
并没有引起大家的兴奋
这背后反映的是一个非常明显的行业变化：
整个AI行业已经进入“实用主义时代”
不再是前两年的“技术崇拜时代”
大家已经从“看模型跑分”进入“看能不能干活”
以前 AI 一升级，我们都会激情转发：
“牛逼！又超越了！”
现在大家打开模型的第一句话变成：
“它能帮我赚到钱吗？”
“能提高多少效率？”
“值不值得花钱？”
Claude 4.5 很强，但它依然是一个聊天框。
没有“炸裂的 demo”应用，没有“改变生活的瞬间”。
强，但不性感。
行业从“最强”转向“最划算”
现在选模型标准已经变成了：
能完成任务最快的
最便宜的
最稳定的
说白了：大家进入 AI 的现实生产阶段了，不烧情怀，烧 ROI。
Claude 太贵、太专业、太不接地气了，它提升的那些东西，普通人感受不到。
而另一边，Nano Banana Pro、Veo、Sora一发布，反而直接让人惊呼：
“这反映出 模型能力的提升不能再让大家感到兴奋，反而是模型出彩应用更让人心头一震”
所以 OpenAI 转为开发各种应用的策略是对的，...

---

## Twitter @歸藏(guizang.ai)

### [Black Forest Labs 发布 FLUX.2，依旧开源！ 支持文生图、多图参考以及图像编辑，文本生成和提示词遵循能力大幅提高。 具体的模型能力有： - 最多同时参考 10 张...](https://x.com/op7418/status/1993347764324122912)

*2025-11-25 15:55*

Black Forest Labs 发布 FLUX.2，依旧开源！
支持文生图、多图参考以及图像编辑，文本生成和提示词遵循能力大幅提高。
具体的模型能力有：
- 最多同时参考 10 张图片，提供最佳一致性。
- 更丰富的细节、更清晰的纹理和更稳定的光线。
- 复杂排版、信息图、表情包和用户界面的文字渲染
- 在遵循复杂、结构化指令方面得到改进
- 现实世界知识、光照和空间逻辑方面显著更有根据
- 支持高达 4MP 分辨率的图像编辑
这次发布了四个模型版本：
FLUX.2 [pro]：与最优秀的封闭模型相媲美的最先进图像质量，在提示遵从性和视觉逼真度方面与其他模型相当，同时生成图像更快且成本更低。速度与质量两者兼得。
FLUX.2 [flex]：可控制模型参数，例如步数和引导强度，让开发者对质量、提示遵从性与速度拥有完全控制。该模型在渲染文本和细节方面表现出色。
FLUX.2 [dev]：32B 开放权重模型，源自 FLUX.2 基础模型。当前最强大的开源图像生成与编辑模型，将文本到图像合成与多输入图像的图像编辑结合在单一模型中。
FLUX.2 [klein]（即将推出）：开源，Apac...

---

### [藏师傅的相去哪儿就去哪儿相机终于发布了正式版！ 我还专门写了个官网来介绍功能，同时增加了三个渠道，保证有一个你是能用。 赶紧来试试：https://bananacamera...](https://x.com/op7418/status/1993304560677667167)

*2025-11-25 13:03*

藏师傅的相去哪儿就去哪儿相机终于发布了正式版！
我还专门写了个官网来介绍功能，同时增加了三个渠道，保证有一个你是能用。
赶紧来试试：https://bananacamera.trickle.host/
歸藏(guizang.ai): 搞了个好玩的，Nano Banana Pro 帮你生成任意位置的打卡照！
用 Gemini 3 写了个工具，只需要在地图上选点，然后上传你的人脸照片，就可以生成你在这个地方的打卡照。
会根据当前位置的天气和时间生成图片，你的衣服也会根据现在的时间以及天气去变化。
人脸一致性真的太高了，我去。...

---

### [有的朋友可能觉得有点花哨 迭代了一下这个 Anthropic 风格的 Nano Banana Pro PPT 提示词。 现在会非常克制的使用插图元素，以及严格遵循网格布局，少用圆润的卡...](https://x.com/op7418/status/1993162900630823106)

*2025-11-25 03:40*

有的朋友可能觉得有点花哨
迭代了一下这个 Anthropic 风格的 Nano Banana Pro PPT 提示词。
现在会非常克制的使用插图元素，以及严格遵循网格布局，少用圆润的卡片。
下面是迭代后的提示词👇
帮我根据下面这个文章做一套专业的的中文PPT。
先写1个PPT大纲，规划出每一页的PPT的内容。
然后将每一页的PPT内容分别扔给Nana Banana pro生成对应页面的PPT，需要确保风格一致。
PPT的具体风格应该为“Anthropic/Claude 风格”的“温暖学术人文主义”设计。
背景：使用暖米色/奶油色 (# F3F0E9) 作为纯色底色，略微高级纸张质感。
字体：标题使用优雅的衬线体（Serif），正文使用现代无衬线体（Sans-serif）。
配色：主色调为赤陶红 (# D67052) 和芥末黄 (# F0B857)，搭配深海军蓝作为点缀。避免使用霓虹色或纯黑色。
视觉元素：使用注重排版的网格布局，插图风格应为抽象的、有机的黑色手绘线条画，置于赤陶红纯色色块之上，你需要非常克制的使用插图和点缀类的插图元素，插图需要为内容服务。
图表：扁平化、极简的图表，强...

---

